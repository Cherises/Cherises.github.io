<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>ç¬¬ä¸€ä¸ªå¾®è°ƒè®­ç»ƒæ¨¡å‹ | Leo's Digital Genesis</title><meta name="author" content="Leonardo"><meta name="copyright" content="Leonardo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="ğŸš€ ä» 0 åˆ° 1ï¼šåŸºäº QLoRA å¾®è°ƒä½ çš„ç¬¬ä¸€ä¸ªè€ƒè¯•é¢˜åº“ AI ä¸“å®¶ æœ¬æ•™ç¨‹è®°å½•äº†å¦‚ä½•åˆ©ç”¨è½»é‡çº§çš„ Qwen1.5-1.8B-Chat æ¨¡å‹å’Œ QLoRA æŠ€æœ¯ï¼Œåœ¨æœ‰é™çš„ GPU èµ„æºï¼ˆå¦‚ 6GB æ˜¾å­˜çš„ RTX 3060 Laptopï¼‰ä¸Šï¼ŒæˆåŠŸå¾®è°ƒå‡ºä¸€ä¸ªèƒ½å¤Ÿç²¾ç¡®ã€ä¸“ä¸šåœ°å›ç­”ç‰¹å®šé¢†åŸŸé¢˜åº“çš„ AI ä¸“å®¶ã€‚  ğŸ¯ ä¸€ã€é¡¹ç›®ç›®æ ‡ä¸æŠ€æœ¯é€‰å‹ 1. ç›®æ ‡ å°†ä¸€ä¸ªé€šç”¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å®šåˆ¶åŒ–ï¼Œä½¿">
<meta property="og:type" content="article">
<meta property="og:title" content="ç¬¬ä¸€ä¸ªå¾®è°ƒè®­ç»ƒæ¨¡å‹">
<meta property="og:url" content="https://cherises.github.io/post/2522/index.html">
<meta property="og:site_name" content="Leo&#39;s Digital Genesis">
<meta property="og:description" content="ğŸš€ ä» 0 åˆ° 1ï¼šåŸºäº QLoRA å¾®è°ƒä½ çš„ç¬¬ä¸€ä¸ªè€ƒè¯•é¢˜åº“ AI ä¸“å®¶ æœ¬æ•™ç¨‹è®°å½•äº†å¦‚ä½•åˆ©ç”¨è½»é‡çº§çš„ Qwen1.5-1.8B-Chat æ¨¡å‹å’Œ QLoRA æŠ€æœ¯ï¼Œåœ¨æœ‰é™çš„ GPU èµ„æºï¼ˆå¦‚ 6GB æ˜¾å­˜çš„ RTX 3060 Laptopï¼‰ä¸Šï¼ŒæˆåŠŸå¾®è°ƒå‡ºä¸€ä¸ªèƒ½å¤Ÿç²¾ç¡®ã€ä¸“ä¸šåœ°å›ç­”ç‰¹å®šé¢†åŸŸé¢˜åº“çš„ AI ä¸“å®¶ã€‚  ğŸ¯ ä¸€ã€é¡¹ç›®ç›®æ ‡ä¸æŠ€æœ¯é€‰å‹ 1. ç›®æ ‡ å°†ä¸€ä¸ªé€šç”¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å®šåˆ¶åŒ–ï¼Œä½¿">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/Cherises/Blog-Resource-2/refs/heads/main/photos/genshin/emoj/569.png">
<meta property="article:published_time" content="2025-11-12T20:15:08.000Z">
<meta property="article:modified_time" content="2025-11-12T12:34:01.000Z">
<meta property="article:author" content="Leonardo">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Quantum Computing">
<meta property="article:tag" content="Neural Networks">
<meta property="article:tag" content="Future Tech">
<meta property="article:tag" content="Digital Philosophy">
<meta property="article:tag" content="Cybersecurity">
<meta property="article:tag" content="Blockchain">
<meta property="article:tag" content="Metaverse">
<meta property="article:tag" content="Algorithmic Ethics">
<meta property="article:tag" content="Space Technology">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Cherises/Blog-Resource-2/refs/heads/main/photos/genshin/emoj/569.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ç¬¬ä¸€ä¸ªå¾®è°ƒè®­ç»ƒæ¨¡å‹",
  "url": "https://cherises.github.io/post/2522/",
  "image": "https://raw.githubusercontent.com/Cherises/Blog-Resource-2/refs/heads/main/photos/genshin/emoj/569.png",
  "datePublished": "2025-11-12T20:15:08.000Z",
  "dateModified": "2025-11-12T12:34:01.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "Leonardo",
      "url": "https://github.com/Cherises/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://cherises.github.io/post/2522/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":5,"unescape":false,"languages":{"hits_empty":"No results found for: ${query}","hits_stats":"${hits} articles found"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ç¬¬ä¸€ä¸ªå¾®è°ƒè®­ç»ƒæ¨¡å‹',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/admonition.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@mdi/font/css/materialdesignicons.min.css"><meta name="generator" content="Hexo 7.3.0"></head><body><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg" style="background-image: url(/img/columbina.webp);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/actor-1.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">108</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">149</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">23</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/Wujie/"><i class="fa-fw fas fa-globe"></i><span> WuJie</span></a></div><div class="menus_item"><a class="site-page" href="/Music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></div><div class="menus_item"><a class="site-page" href="/About/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Leo's Digital Genesis</span></a><a class="nav-page-title" href="/"><span class="site-name">ç¬¬ä¸€ä¸ªå¾®è°ƒè®­ç»ƒæ¨¡å‹</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/Wujie/"><i class="fa-fw fas fa-globe"></i><span> WuJie</span></a></div><div class="menus_item"><a class="site-page" href="/Music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></div><div class="menus_item"><a class="site-page" href="/About/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">ç¬¬ä¸€ä¸ªå¾®è°ƒè®­ç»ƒæ¨¡å‹</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-11-12T20:15:08.000Z" title="Created 2025-11-12 20:15:08">2025-11-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-11-12T12:34:01.000Z" title="Updated 2025-11-12 12:34:01">2025-11-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/study/">study</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">4.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>20mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h1 id="ğŸš€-ä»-0-åˆ°-1ï¼šåŸºäº-QLoRA-å¾®è°ƒä½ çš„ç¬¬ä¸€ä¸ªè€ƒè¯•é¢˜åº“-AI-ä¸“å®¶"><a href="#ğŸš€-ä»-0-åˆ°-1ï¼šåŸºäº-QLoRA-å¾®è°ƒä½ çš„ç¬¬ä¸€ä¸ªè€ƒè¯•é¢˜åº“-AI-ä¸“å®¶" class="headerlink" title="ğŸš€ ä» 0 åˆ° 1ï¼šåŸºäº QLoRA å¾®è°ƒä½ çš„ç¬¬ä¸€ä¸ªè€ƒè¯•é¢˜åº“ AI ä¸“å®¶"></a>ğŸš€ ä» 0 åˆ° 1ï¼šåŸºäº QLoRA å¾®è°ƒä½ çš„ç¬¬ä¸€ä¸ªè€ƒè¯•é¢˜åº“ AI ä¸“å®¶</h1><blockquote>
<p>æœ¬æ•™ç¨‹è®°å½•äº†å¦‚ä½•åˆ©ç”¨è½»é‡çº§çš„ <strong>Qwen1.5-1.8B-Chat</strong> æ¨¡å‹å’Œ <strong>QLoRA</strong> æŠ€æœ¯ï¼Œåœ¨æœ‰é™çš„ GPU èµ„æºï¼ˆå¦‚ 6GB æ˜¾å­˜çš„ RTX 3060 Laptopï¼‰ä¸Šï¼ŒæˆåŠŸå¾®è°ƒå‡ºä¸€ä¸ªèƒ½å¤Ÿç²¾ç¡®ã€ä¸“ä¸šåœ°å›ç­”ç‰¹å®šé¢†åŸŸé¢˜åº“çš„ AI ä¸“å®¶ã€‚</p>
</blockquote>
<h2 id="ğŸ¯-ä¸€ã€é¡¹ç›®ç›®æ ‡ä¸æŠ€æœ¯é€‰å‹"><a href="#ğŸ¯-ä¸€ã€é¡¹ç›®ç›®æ ‡ä¸æŠ€æœ¯é€‰å‹" class="headerlink" title="ğŸ¯ ä¸€ã€é¡¹ç›®ç›®æ ‡ä¸æŠ€æœ¯é€‰å‹"></a>ğŸ¯ ä¸€ã€é¡¹ç›®ç›®æ ‡ä¸æŠ€æœ¯é€‰å‹</h2><h3 id="1-ç›®æ ‡"><a href="#1-ç›®æ ‡" class="headerlink" title="1. ç›®æ ‡"></a>1. ç›®æ ‡</h3><p>å°†ä¸€ä¸ªé€šç”¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å®šåˆ¶åŒ–ï¼Œä½¿å…¶èƒ½å¤Ÿåƒä¸“ä¸šçš„æ•™å¸ˆæˆ–é¢˜åº“ç³»ç»Ÿä¸€æ ·ï¼Œä»¥ç»“æ„åŒ–ã€é«˜å‡†ç¡®ç‡çš„æ–¹å¼å›ç­”æˆ‘ä»¬æä¾›çš„ <strong>å‡ åƒé“ç‰¹å®šé¢†åŸŸçš„è€ƒè¯•é¢˜ç›®</strong>ã€‚</p>
<h3 id="2-æŠ€æœ¯é€‰å‹"><a href="#2-æŠ€æœ¯é€‰å‹" class="headerlink" title="2. æŠ€æœ¯é€‰å‹"></a>2. æŠ€æœ¯é€‰å‹</h3><ul>
<li><strong>åŸºç¡€æ¨¡å‹ (Base Model):</strong> <strong>Qwen&#x2F;Qwen1.5-1.8B-Chat</strong>ã€‚<ul>
<li><strong>åŸå› :</strong> ä½“ç§¯å°ï¼ˆ18äº¿å‚æ•°ï¼‰ï¼Œå¯¹ VRAM å‹å¥½ï¼›åŸºäº Qwen ç»“æ„ï¼Œä¸­æ–‡å¤„ç†èƒ½åŠ›å¼ºï¼ŒåŒæ—¶æ”¯æŒ Chat åŠŸèƒ½ã€‚</li>
</ul>
</li>
<li><strong>å¾®è°ƒæ–¹æ³• (Fine-tuning):</strong> <strong>QLoRA (Quantized Low-Rank Adaptation)</strong>ã€‚<ul>
<li><strong>åŸå› :</strong> åœ¨ 4-bit é‡åŒ–æ¨¡å‹ä¸Šè¿›è¡Œ LoRA è®­ç»ƒï¼Œæå¤§åœ°é™ä½äº† VRAM å ç”¨ï¼Œä½¿ 6GB æ˜¾å­˜çš„ GPU ä¹Ÿèƒ½è¿›è¡Œè®­ç»ƒã€‚</li>
</ul>
</li>
</ul>
<hr>
<h2 id="ğŸ› ï¸-äºŒã€ç¯å¢ƒä¸æ•°æ®å‡†å¤‡"><a href="#ğŸ› ï¸-äºŒã€ç¯å¢ƒä¸æ•°æ®å‡†å¤‡" class="headerlink" title="ğŸ› ï¸ äºŒã€ç¯å¢ƒä¸æ•°æ®å‡†å¤‡"></a>ğŸ› ï¸ äºŒã€ç¯å¢ƒä¸æ•°æ®å‡†å¤‡</h2><h3 id="1-åŸºç¡€ç¯å¢ƒé…ç½®"><a href="#1-åŸºç¡€ç¯å¢ƒé…ç½®" class="headerlink" title="1. åŸºç¡€ç¯å¢ƒé…ç½®"></a>1. åŸºç¡€ç¯å¢ƒé…ç½®</h3><p>è¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒå·²å®‰è£…ä»¥ä¸‹å…³é”®åº“ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®‰è£… pytorch (å¸¦ CUDA æ”¯æŒ)</span></span><br><span class="line">conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®‰è£… transformers, peft, accelerate, bitsandbytes (QLoRA æ ¸å¿ƒä¾èµ–)</span></span><br><span class="line">pip install transformers peft accelerate bitsandbytes</span><br><span class="line"><span class="comment"># å®‰è£… huggingface_hub å’Œ datasets (æ•°æ®å¤„ç†ä¸æ¨¡å‹ä¸‹è½½)</span></span><br><span class="line">pip install datasets huggingface_hub pandas sqlalchemy pyarrow</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>æ³¨æ„:</strong> å¦‚æœä¸‹è½½æ¨¡å‹é‡åˆ° <code>404</code> é”™è¯¯ï¼Œè¯·åœ¨ç»ˆç«¯æ‰§è¡Œ <code>huggingface-cli login</code> è¿›è¡Œç™»å½•è®¤è¯ã€‚</p>
</blockquote>
<h3 id="2-æ•°æ®æ ¼å¼åŒ–-1-data-prep-py"><a href="#2-æ•°æ®æ ¼å¼åŒ–-1-data-prep-py" class="headerlink" title="2. æ•°æ®æ ¼å¼åŒ– (1_data_prep.py)"></a>2. æ•°æ®æ ¼å¼åŒ– (<code>1_data_prep.py</code>)</h3><p>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†æ•°æ®åº“ä¸­çš„é¢˜åº“æ ¼å¼åŒ–ä¸º LLM å¾®è°ƒæ‰€éœ€çš„ <strong>æŒ‡ä»¤å¾®è°ƒ (Instruction Tuning)</strong> æ ¼å¼ï¼š<code>&#123;instruction, input, output&#125;</code>ã€‚</p>
<ul>
<li><strong><code>instruction</code> (æŒ‡ä»¤):</strong> å›ºå®šçš„ä»»åŠ¡æè¿°ï¼Œå¦‚â€œè¯·æ ¹æ®æä¾›çš„é¢˜ç›®ä¿¡æ¯ï¼Œç»™å‡ºæ­£ç¡®ç­”æ¡ˆä»¥åŠè¯¦ç»†çš„è§£æã€‚â€</li>
<li><strong><code>input</code> (è¾“å…¥):</strong> é¢˜ç›®çš„å…¨éƒ¨ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç§‘ç›®ã€ç±»å‹ã€é¢˜å¹²ã€æ‰€æœ‰é€‰é¡¹ã€‚</li>
<li><strong><code>output</code> (è¾“å‡º):</strong> æ ‡å‡†ç­”æ¡ˆå’Œè¯¦ç»†è§£æã€‚</li>
</ul>
<p>æœ€ç»ˆç”Ÿæˆçš„æ–‡ä»¶æ˜¯ <code>instruction_data.jsonl</code>ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ ¸å¿ƒä»£ç ç‰‡æ®µ (1_data_prep.py)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">export_and_format_data</span>(<span class="params">db_url, output_file</span>):</span><br><span class="line">    <span class="comment"># ... (æ•°æ®åº“è¿æ¥å’Œè¯»å–ä»£ç ) ...</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        input_text = <span class="string">f&quot;ç§‘ç›®ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_subjects&#x27;</span>]&#125;</span>\né¢˜ç›®ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_question&#x27;</span>]&#125;</span>\n\n&quot;</span></span><br><span class="line">        <span class="comment"># ... (åŠ¨æ€æ·»åŠ é€‰é¡¹) ...</span></span><br><span class="line">        </span><br><span class="line">        output_text = <span class="string">f&quot;ã€æ­£ç¡®ç­”æ¡ˆã€‘ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_answer&#x27;</span>]&#125;</span>\n&quot;</span></span><br><span class="line">        output_text += <span class="string">f&quot;ã€è¯¦ç»†è§£æã€‘ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_explanation&#x27;</span>] <span class="keyword">or</span> <span class="string">&#x27;æš‚æ— è§£æ&#x27;</span>&#125;</span>&quot;</span></span><br><span class="line">        </span><br><span class="line">        formatted_data.append(&#123;</span><br><span class="line">            <span class="string">&quot;instruction&quot;</span>: INSTRUCTION,</span><br><span class="line">            <span class="string">&quot;input&quot;</span>: input_text.strip(),</span><br><span class="line">            <span class="string">&quot;output&quot;</span>: output_text.strip()</span><br><span class="line">        &#125;)</span><br><span class="line">    <span class="comment"># ... (å†™å…¥ jsonl æ–‡ä»¶) ...</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="âš™ï¸-ä¸‰ã€QLoRA-æ¨¡å‹å¾®è°ƒ-2-qlora-finetune-py"><a href="#âš™ï¸-ä¸‰ã€QLoRA-æ¨¡å‹å¾®è°ƒ-2-qlora-finetune-py" class="headerlink" title="âš™ï¸ ä¸‰ã€QLoRA æ¨¡å‹å¾®è°ƒ (2_qlora_finetune.py)"></a>âš™ï¸ ä¸‰ã€QLoRA æ¨¡å‹å¾®è°ƒ (<code>2_qlora_finetune.py</code>)</h2><h3 id="1-QLoRA-æ ¸å¿ƒé…ç½®"><a href="#1-QLoRA-æ ¸å¿ƒé…ç½®" class="headerlink" title="1. QLoRA æ ¸å¿ƒé…ç½®"></a>1. QLoRA æ ¸å¿ƒé…ç½®</h3><p>ä¸ºé€‚åº” 6GB æ˜¾å­˜ï¼Œæˆ‘ä»¬åšäº†ä»¥ä¸‹å…³é”®ä¼˜åŒ–ï¼š</p>
<ul>
<li><strong>æ¨¡å‹:</strong> Qwen&#x2F;Qwen1.5-1.8B-Chat</li>
<li><strong>é‡åŒ–:</strong> <code>BitsAndBytesConfig</code> å¯ç”¨ 4-bit NF4 é‡åŒ–ã€‚</li>
<li><strong>åºåˆ—é•¿åº¦:</strong> <code>MAX_LENGTH = 384</code> (æœ€å¤§è¾“å…¥åºåˆ—é•¿åº¦ï¼Œå‡å°‘ VRAM å ç”¨)ã€‚</li>
<li><strong>è®­ç»ƒå‚æ•° (<code>TrainingArguments</code>):</strong><ul>
<li><code>per_device_train_batch_size=1</code>: å•æ­¥ Batch Size é™è‡³æœ€ä½ã€‚</li>
<li><code>gradient_accumulation_steps=8</code>: é€šè¿‡æ¢¯åº¦ç´¯ç§¯ï¼Œå®ç°ç­‰æ•ˆ Batch Size ä¸º 8ï¼Œä¿è¯è®­ç»ƒæ•ˆæœã€‚</li>
</ul>
</li>
</ul>
<h3 id="2-è®­ç»ƒè„šæœ¬-2-qlora-finetune-py-è¿è¡Œ"><a href="#2-è®­ç»ƒè„šæœ¬-2-qlora-finetune-py-è¿è¡Œ" class="headerlink" title="2. è®­ç»ƒè„šæœ¬ (2_qlora_finetune.py) è¿è¡Œ"></a>2. è®­ç»ƒè„šæœ¬ (<code>2_qlora_finetune.py</code>) è¿è¡Œ</h3><p>è¿è¡Œè„šæœ¬å¼€å§‹è®­ç»ƒï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&amp; C:/Users/zhaoz/anaconda3/python.exe c:/Users/zhaoz/Desktop/å¤§æ¨¡å‹è®­ç»ƒ/2_qlora_finetune.py</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">æŒ‡æ ‡</th>
<th align="left">è®­ç»ƒåˆæœŸè¡¨ç°</th>
<th align="left">ä¼˜åŒ–æ•ˆæœ</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>VRAM å ç”¨</strong></td>
<td align="left">çº¦ 5GB &#x2F; 6GB</td>
<td align="left">QLoRA æˆåŠŸï¼ŒVRAM å®‰å…¨ã€‚</td>
</tr>
<tr>
<td align="left"><strong>è®­ç»ƒé€Ÿåº¦</strong></td>
<td align="left">çº¦ 4-5 ç§’&#x2F;æ­¥ (Step)</td>
<td align="left">æ¯” 7B æ¨¡å‹åŠ é€Ÿ 10 å€ä»¥ä¸Šï¼Œæ€»è®­ç»ƒæ—¶é•¿é™è‡³çº¦ 1.5 å°æ—¶å†…ã€‚</td>
</tr>
<tr>
<td align="left"><strong>GPU çŠ¶æ€</strong></td>
<td align="left">åŠŸç‡è·‘æ»¡ (å¦‚ 99W&#x2F;115W)</td>
<td align="left">GPU èµ„æºå¾—åˆ°å……åˆ†åˆ©ç”¨ã€‚</td>
</tr>
</tbody></table>
<hr>
<h2 id="ğŸ§ª-å››ã€æ¨¡å‹è°ƒç”¨ä¸æ•ˆæœæµ‹è¯•-3-inference-py"><a href="#ğŸ§ª-å››ã€æ¨¡å‹è°ƒç”¨ä¸æ•ˆæœæµ‹è¯•-3-inference-py" class="headerlink" title="ğŸ§ª å››ã€æ¨¡å‹è°ƒç”¨ä¸æ•ˆæœæµ‹è¯• (3_inference.py)"></a>ğŸ§ª å››ã€æ¨¡å‹è°ƒç”¨ä¸æ•ˆæœæµ‹è¯• (<code>3_inference.py</code>)</h2><p>è®­ç»ƒå®Œæˆåï¼ŒLoRA æƒé‡è¢«ä¿å­˜åˆ° <code>./qwen1.5_1.8b_lora</code> ç›®å½•ã€‚æˆ‘ä»¬é€šè¿‡ <code>PeftModel</code> å°† LoRA æƒé‡æ³¨å…¥åˆ°é‡åŒ–åçš„åŸºç¡€æ¨¡å‹ä¸­ã€‚</p>
<h3 id="1-æ ¸å¿ƒè°ƒç”¨é€»è¾‘"><a href="#1-æ ¸å¿ƒè°ƒç”¨é€»è¾‘" class="headerlink" title="1. æ ¸å¿ƒè°ƒç”¨é€»è¾‘"></a>1. æ ¸å¿ƒè°ƒç”¨é€»è¾‘</h3><p>æ¨ç†è„šæœ¬çš„å…³é”®åœ¨äºä½¿ç”¨ <code>PeftModel.from_pretrained(model, OUTPUT_DIR)</code>ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ ¸å¿ƒä»£ç ç‰‡æ®µ (3_inference.py)</span></span><br><span class="line"><span class="comment"># 1. åŠ è½½é‡åŒ–åçš„åŸºç¡€æ¨¡å‹</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(...) </span><br><span class="line"><span class="comment"># 2. æ³¨å…¥ LoRA é€‚é…å™¨</span></span><br><span class="line">model = PeftModel.from_pretrained(model, OUTPUT_DIR)</span><br><span class="line">model.<span class="built_in">eval</span>() <span class="comment"># åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼</span></span><br><span class="line"><span class="comment"># 3. æ„é€ ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„ Prompt è¿›è¡Œç”Ÿæˆ</span></span><br><span class="line">prompt = <span class="string">f&quot;### Instruction:\n<span class="subst">&#123;instruction&#125;</span>\n\n### Input:\n<span class="subst">&#123;input_text&#125;</span>\n\n### Response:\n&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="2-æ•ˆæœæµ‹è¯•ç¤ºä¾‹"><a href="#2-æ•ˆæœæµ‹è¯•ç¤ºä¾‹" class="headerlink" title="2. æ•ˆæœæµ‹è¯•ç¤ºä¾‹"></a>2. æ•ˆæœæµ‹è¯•ç¤ºä¾‹</h3><p>é€šè¿‡äº¤äº’å¼æµ‹è¯•ï¼Œæˆ‘ä»¬éªŒè¯äº†å¾®è°ƒåçš„æ•ˆæœï¼š</p>
<p><strong>æµ‹è¯•æŒ‡ä»¤ï¼š</strong> ä»€ä¹ˆæ˜¯é©¬å…‹æ€ä¸»ä¹‰ï¼Ÿé©¬å…‹æ€ä¸»ä¹‰å…·æœ‰å“ªäº›é²œæ˜çš„ç‰¹å¾ï¼Ÿ<br><strong>Input æ–‡æœ¬ï¼š</strong> (ç©º)</p>
<p><strong>å¾®è°ƒæ¨¡å‹å“åº”ï¼š</strong></p>
<blockquote>
<p>ã€ä¸€ã€‘é©¬å…‹æ€ä¸»ä¹‰æ˜¯å…³äºæ— äº§é˜¶çº§å’Œäººç±»è§£æ”¾çš„æ”¿æ²»ç»æµå­¦ã€‚<br>ã€äºŒã€‘é©¬å…‹æ€ä¸»ä¹‰å…·æœ‰ä»¥ä¸‹ä¸‰ä¸ªæ˜¾è‘—ç‰¹ç‚¹ï¼š</p>
<ol>
<li>é©¬å…‹æ€ä¸»ä¹‰æ˜¯ä¸€ä¸ªæœ‰æœºçš„æ•´ä½“ï¼Œå®ƒæ˜¯é©¬å…‹æ€æ©æ ¼æ–¯åˆ›ç«‹çš„ç§‘å­¦ç¤¾ä¼šä¸»ä¹‰ç†è®ºä½“ç³»ï¼›</li>
<li>é©¬å…‹æ€ä¸»ä¹‰æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç†è®ºä½“ç³»â€¦</li>
<li>é©¬å…‹æ€ä¸»ä¹‰æ˜¯ä¸€ä¸ªä¸æ–­å‘å±•å’Œå®Œå–„çš„è¿‡ç¨‹â€¦</li>
</ol>
</blockquote>
<p><strong>ç»“è®º:</strong> æ¨¡å‹èƒ½å¤Ÿç²¾ç¡®åœ°éµå¾ªè®­ç»ƒæ•°æ®ä¸­çš„<strong>ç»“æ„åŒ–æ ¼å¼</strong>ï¼ˆä½¿ç”¨ <code>ã€ä¸€ã€‘</code>ã€<code>ã€äºŒã€‘</code>ã€<code>1.</code> ç­‰ï¼‰ï¼Œå¹¶ç»™å‡º<strong>ä¸“ä¸šã€é«˜ç›¸å…³æ€§</strong>çš„ç­”æ¡ˆã€‚</p>
<hr>
<h2 id="ğŸ’¡-äº”ã€æ€»ç»“ä¸å¿ƒå¾—ä½“ä¼š"><a href="#ğŸ’¡-äº”ã€æ€»ç»“ä¸å¿ƒå¾—ä½“ä¼š" class="headerlink" title="ğŸ’¡ äº”ã€æ€»ç»“ä¸å¿ƒå¾—ä½“ä¼š"></a>ğŸ’¡ äº”ã€æ€»ç»“ä¸å¿ƒå¾—ä½“ä¼š</h2><h3 id="QLoRA-å¾®è°ƒçš„çœŸæ­£ä»·å€¼"><a href="#QLoRA-å¾®è°ƒçš„çœŸæ­£ä»·å€¼" class="headerlink" title="QLoRA å¾®è°ƒçš„çœŸæ­£ä»·å€¼"></a>QLoRA å¾®è°ƒçš„çœŸæ­£ä»·å€¼</h3><table>
<thead>
<tr>
<th align="left">ä½ çš„æ¨¡å‹ (å¾®è°ƒå)</th>
<th align="left">Ollama é€šç”¨æ¨¡å‹ (æœªå¾®è°ƒ)</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>ä¸“å®¶åŒ–ï¼š</strong> æˆä¸ºç‰¹å®šé¢˜åº“çŸ¥è¯†çš„æƒå¨ä¸“å®¶ã€‚</td>
<td align="left"><strong>é€šç”¨æ€§ï¼š</strong> çŸ¥è¯†å¹¿åšï¼Œä½†ç‰¹å®šé¢†åŸŸä¸æƒå¨ã€‚</td>
</tr>
<tr>
<td align="left"><strong>ç»“æ„åŒ–è¾“å‡ºï¼š</strong> å¼ºåˆ¶éµå¾ªè®­ç»ƒæ•°æ®ä¸­çš„æ ¼å¼ï¼ˆå¦‚ï¼šã€æ­£ç¡®ç­”æ¡ˆã€‘ã€ã€è¯¦ç»†è§£æã€‘ï¼‰ã€‚</td>
<td align="left"><strong>è‡ªç”±è¾“å‡ºï¼š</strong> å›ç­”æ ¼å¼å¤šæ ·ã€çµæ´»ï¼Œç¼ºä¹ä¸€è‡´æ€§ã€‚</td>
</tr>
<tr>
<td align="left"><strong>çŸ¥è¯†æƒé‡å¼ºåŒ–ï¼š</strong> ä¼˜å…ˆã€å‡†ç¡®åœ°è°ƒç”¨è®­ç»ƒæ•°æ®ä¸­çš„æ ‡å‡†ç­”æ¡ˆã€‚</td>
<td align="left"><strong>çŸ¥è¯†åˆ†æ•£ï¼š</strong> å›ç­”å¯èƒ½åŒ…å«éæ ‡å‡†æˆ–è¿‡æ—¶çš„ä¿¡æ¯ã€‚</td>
</tr>
<tr>
<td align="left"><strong>æ¨ç†é€Ÿåº¦ï¼š</strong> æ¨¡å‹æ›´å°ï¼ˆ1.8Bï¼‰ä¸”å›ç­”æ”¶æ•›å¿«ï¼Œ<strong>é€Ÿåº¦æ›´å¿«</strong>ã€‚</td>
<td align="left"><strong>æ¨ç†é€Ÿåº¦ï¼š</strong> æ¨¡å‹è¾ƒå¤§ï¼ˆé€šå¸¸ &gt; 7Bï¼‰ä¸”éœ€è¦æ›´å¤šâ€œæ€è€ƒâ€æ­¥éª¤ï¼Œé€Ÿåº¦è¾ƒæ…¢ã€‚</td>
</tr>
</tbody></table>
<p>å¾®è°ƒçš„æ„ä¹‰åœ¨äºï¼š<strong>å®ƒæ•™ä¼šäº†æ¨¡å‹â€œå¦‚ä½•â€ä½¿ç”¨è¿™äº›çŸ¥è¯†ï¼Œä»¥åŠâ€œå¦‚ä½•â€ä»¥ä½ æœŸæœ›çš„ä¸“ä¸šæ ¼å¼è¿›è¡Œå›å¤ã€‚</strong> è¿™ä¸ä»…ä»…æ˜¯ç®€å•çš„â€œè®°ä½ç­”æ¡ˆâ€ï¼Œè€Œæ˜¯å®ç°äº†<strong>è¡Œä¸ºå’ŒçŸ¥è¯†çš„å¯¹é½</strong>ã€‚</p>
<h3 id="ç»éªŒæ€»ç»“"><a href="#ç»éªŒæ€»ç»“" class="headerlink" title="ç»éªŒæ€»ç»“"></a>ç»éªŒæ€»ç»“</h3><ol>
<li><strong>æ¨¡å‹é€‰æ‹©è‡³å…³é‡è¦ï¼š</strong> åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œé€‰æ‹© 1.8B çº§åˆ«çš„è½»é‡æ¨¡å‹ï¼ˆå¦‚ Qwen1.5-1.8B-Chatï¼‰æ˜¯æˆåŠŸçš„å…³é”®ã€‚</li>
<li><strong>Prompt æ ¼å¼ä¸€è‡´æ€§ï¼š</strong> è®­ç»ƒï¼ˆ<code>2_qlora_finetune.py</code>ï¼‰å’Œæ¨ç†ï¼ˆ<code>3_inference.py</code>ï¼‰ä¸­çš„ Prompt æ¨¡æ¿ï¼ˆå¦‚ <code>### Instruction:\n...</code>ï¼‰å¿…é¡»<strong>å®Œå…¨ä¸€è‡´</strong>ï¼Œå¦åˆ™æ¨¡å‹å°†æ— æ³•ç†è§£ä½ çš„æŒ‡ä»¤ã€‚</li>
<li><strong>ç½‘ç»œç¨³å®šæ€§æŒ‘æˆ˜ï¼š</strong> å³ä½¿æ˜¯æ­£ç¡®çš„æ¨¡å‹ IDï¼Œä¸‹è½½æ—¶ä¹Ÿå¯èƒ½å› ç½‘ç»œæˆ– SSL é—®é¢˜é­é‡é¡½å›ºçš„ <code>404</code> é”™è¯¯ã€‚é‡åˆ°é—®é¢˜æ—¶ï¼Œåº”ä¼˜å…ˆ<strong>é‡å¼€ç»ˆç«¯ã€æ¸…ç†ç¯å¢ƒå˜é‡</strong>ï¼Œæˆ–ä½¿ç”¨ç¨³å®šé•œåƒæºã€‚</li>
</ol>
<hr>
<p><code>1_data_prep.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- é…ç½® ---</span></span><br><span class="line"><span class="comment"># æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²ï¼šæ ¹æ®æ‚¨çš„æ•°æ®åº“ç±»å‹ä¿®æ”¹</span></span><br><span class="line"><span class="comment"># ä¾‹å¦‚ï¼šSQLite: &#x27;sqlite:///your_database_name.db&#x27;</span></span><br><span class="line"><span class="comment"># ä¾‹å¦‚ï¼šMySQL: &#x27;mysql+pymysql://user:password@host/db_name&#x27;</span></span><br><span class="line">DATABASE_URL = <span class="string">&quot;sqlite:///everything.db&quot;</span> </span><br><span class="line">OUTPUT_FILE = <span class="string">&quot;instruction_data.jsonl&quot;</span></span><br><span class="line">INSTRUCTION = <span class="string">&quot;è¯·æ ¹æ®æä¾›çš„é¢˜ç›®ä¿¡æ¯ï¼Œç»™å‡ºæ­£ç¡®ç­”æ¡ˆä»¥åŠè¯¦ç»†çš„è§£æã€‚&quot;</span></span><br><span class="line"><span class="comment"># ----------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">export_and_format_data</span>(<span class="params">db_url, output_file</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;ä»æ•°æ®åº“è¯»å–é¢˜åº“ï¼Œå¹¶æ ¼å¼åŒ–ä¸ºæŒ‡ä»¤å¾®è°ƒæ‰€éœ€çš„ JSONL æ ¼å¼ã€‚&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;å°è¯•è¿æ¥æ•°æ®åº“ï¼š<span class="subst">&#123;db_url&#125;</span>&quot;</span>)</span><br><span class="line">    engine = create_engine(db_url)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># å‡è®¾æ‚¨çš„è¡¨åä¸º practice_questions</span></span><br><span class="line">    df = pd.read_sql(<span class="string">&quot;SELECT * FROM practice_questions&quot;</span>, engine)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;æˆåŠŸè¯»å– <span class="subst">&#123;<span class="built_in">len</span>(df)&#125;</span> æ¡é¢˜ç›®æ•°æ®ã€‚&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    formatted_data = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        <span class="comment"># 1. æ„å»º INPUT å­—æ®µ (åŒ…å«æ‰€æœ‰é¢˜ç›®å’Œé€‰é¡¹ä¿¡æ¯)</span></span><br><span class="line">        input_text = <span class="string">f&quot;ç§‘ç›®ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_subjects&#x27;</span>]&#125;</span>\n&quot;</span></span><br><span class="line">        input_text += <span class="string">f&quot;ç±»å‹ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_type&#x27;</span>]&#125;</span>\n&quot;</span></span><br><span class="line">        input_text += <span class="string">f&quot;ç« èŠ‚ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_chapter&#x27;</span>] <span class="keyword">or</span> <span class="string">&#x27;N/A&#x27;</span>&#125;</span>\n&quot;</span></span><br><span class="line">        input_text += <span class="string">f&quot;é¢˜ç›®ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_question&#x27;</span>]&#125;</span>\n\n&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># åŠ¨æ€æ·»åŠ é€‰é¡¹ï¼Œå¤„ç†å¯èƒ½çš„ None/NaN å€¼</span></span><br><span class="line">        options = &#123;</span><br><span class="line">            <span class="string">&#x27;A&#x27;</span>: row.get(<span class="string">&#x27;p_option_a&#x27;</span>), <span class="string">&#x27;B&#x27;</span>: row.get(<span class="string">&#x27;p_option_b&#x27;</span>),</span><br><span class="line">            <span class="string">&#x27;C&#x27;</span>: row.get(<span class="string">&#x27;p_option_c&#x27;</span>), <span class="string">&#x27;D&#x27;</span>: row.get(<span class="string">&#x27;p_option_d&#x27;</span>),</span><br><span class="line">            <span class="string">&#x27;E&#x27;</span>: row.get(<span class="string">&#x27;p_option_e&#x27;</span>), <span class="string">&#x27;F&#x27;</span>: row.get(<span class="string">&#x27;p_option_f&#x27;</span>),</span><br><span class="line">            <span class="string">&#x27;G&#x27;</span>: row.get(<span class="string">&#x27;p_option_g&#x27;</span>),</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        valid_options = [<span class="string">f&quot;é€‰é¡¹<span class="subst">&#123;k&#125;</span>ï¼š<span class="subst">&#123;v&#125;</span>&quot;</span> <span class="keyword">for</span> k, v <span class="keyword">in</span> options.items() <span class="keyword">if</span> pd.notna(v) <span class="keyword">and</span> v <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>]</span><br><span class="line">        input_text += <span class="string">&quot;\n&quot;</span>.join(valid_options)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. æ„å»º OUTPUT å­—æ®µ (æ ‡å‡†ç­”æ¡ˆå’Œè§£æ)</span></span><br><span class="line">        output_text = <span class="string">f&quot;ã€æ­£ç¡®ç­”æ¡ˆã€‘ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_answer&#x27;</span>]&#125;</span>\n&quot;</span></span><br><span class="line">        output_text += <span class="string">f&quot;ã€è¯¦ç»†è§£æã€‘ï¼š<span class="subst">&#123;row[<span class="string">&#x27;p_explanation&#x27;</span>] <span class="keyword">or</span> <span class="string">&#x27;æš‚æ— è§£æ&#x27;</span>&#125;</span>&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. æ„é€ æœ€ç»ˆçš„ JSON æ ¼å¼</span></span><br><span class="line">        formatted_data.append(&#123;</span><br><span class="line">            <span class="string">&quot;instruction&quot;</span>: INSTRUCTION,</span><br><span class="line">            <span class="string">&quot;input&quot;</span>: input_text.strip(),</span><br><span class="line">            <span class="string">&quot;output&quot;</span>: output_text.strip()</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># å°†æ•°æ®å†™å…¥ JSONL æ–‡ä»¶</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(output_file, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> formatted_data:</span><br><span class="line">            f.write(json.dumps(item, ensure_ascii=<span class="literal">False</span>) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\næ•°æ®æ ¼å¼åŒ–å®Œæˆï¼Œå·²ä¿å­˜åˆ° <span class="subst">&#123;output_file&#125;</span>ï¼Œå…± <span class="subst">&#123;<span class="built_in">len</span>(formatted_data)&#125;</span> æ¡è®°å½•ã€‚&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># åœ¨è¿è¡Œå‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²ä¿®æ”¹ DATABASE_URL </span></span><br><span class="line">    export_and_format_data(DATABASE_URL, OUTPUT_FILE)</span><br></pre></td></tr></table></figure>
<hr>
<p><code>2_qlora_finetune.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (</span><br><span class="line">    AutoModelForCausalLM,</span><br><span class="line">    AutoTokenizer,</span><br><span class="line">    TrainingArguments,</span><br><span class="line">    Trainer,</span><br><span class="line">    BitsAndBytesConfig,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, get_peft_model, prepare_model_for_kbit_training</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- åŸºç¡€å‚æ•° ---</span></span><br><span class="line">BASE_MODEL = <span class="string">&quot;Qwen/Qwen1.5-1.8B-Chat&quot;</span>   <span class="comment"># âœ… æ”¹ç”¨è½»é‡ç‰ˆ</span></span><br><span class="line">DATA_PATH = <span class="string">&quot;instruction_data.jsonl&quot;</span></span><br><span class="line">OUTPUT_DIR = <span class="string">&quot;./qwen1.5_1.8b_lora&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># LoRA å‚æ•°</span></span><br><span class="line">LORA_R = <span class="number">16</span></span><br><span class="line">LORA_ALPHA = <span class="number">32</span></span><br><span class="line">LORA_DROPOUT = <span class="number">0.05</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å…³é”®æ˜¾å­˜ä¼˜åŒ–å‚æ•°</span></span><br><span class="line">MAX_LENGTH = <span class="number">384</span>  <span class="comment"># âœ… å†æ¬¡é™ä½åºåˆ—é•¿åº¦</span></span><br><span class="line">MAX_VRAM_GB = <span class="number">5.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 1. æ•°æ®é¢„å¤„ç†</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">format_prompt</span>(<span class="params">sample</span>):</span><br><span class="line">    text = <span class="string">f&quot;### Instruction:\n<span class="subst">&#123;sample[<span class="string">&#x27;instruction&#x27;</span>]&#125;</span>\n\n### Input:\n<span class="subst">&#123;sample[<span class="string">&#x27;input&#x27;</span>]&#125;</span>\n\n### Response:\n<span class="subst">&#123;sample[<span class="string">&#x27;output&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: text&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;åŠ è½½å¹¶æ ¼å¼åŒ–æ•°æ®é›†...&quot;</span>)</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=DATA_PATH)</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(format_prompt, batched=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">dataset = dataset[<span class="string">&quot;train&quot;</span>].train_test_split(test_size=<span class="number">0.05</span>)</span><br><span class="line">train_data = dataset[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">val_data = dataset[<span class="string">&quot;test&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;è®­ç»ƒé›†å¤§å°: <span class="subst">&#123;<span class="built_in">len</span>(train_data)&#125;</span>, éªŒè¯é›†å¤§å°: <span class="subst">&#123;<span class="built_in">len</span>(val_data)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 2. åŠ è½½æ¨¡å‹ (QLoRA)</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;æ­£åœ¨åŠ è½½åŸºç¡€æ¨¡å‹: <span class="subst">&#123;BASE_MODEL&#125;</span> (4-bit é‡åŒ–)...&quot;</span>)</span><br><span class="line"></span><br><span class="line">bnb_config = BitsAndBytesConfig(</span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">    bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>,</span><br><span class="line">    bnb_4bit_compute_dtype=torch.float16,</span><br><span class="line">    bnb_4bit_use_double_quant=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">max_memory = &#123;</span><br><span class="line">    <span class="number">0</span>: <span class="string">f&#x27;<span class="subst">&#123;<span class="built_in">int</span>(MAX_VRAM_GB * <span class="number">1024</span>)&#125;</span>MiB&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cpu&#x27;</span>: <span class="string">&#x27;30GiB&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    BASE_MODEL,</span><br><span class="line">    quantization_config=bnb_config,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    max_memory=max_memory,</span><br><span class="line">    low_cpu_mem_usage=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 3. åˆ†è¯ä¸æ ‡ç­¾</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">sample</span>):</span><br><span class="line">    tokens = tokenizer(</span><br><span class="line">        sample[<span class="string">&quot;text&quot;</span>],</span><br><span class="line">        max_length=MAX_LENGTH,</span><br><span class="line">        truncation=<span class="literal">True</span>,</span><br><span class="line">        padding=<span class="string">&quot;max_length&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;input_ids&quot;</span>: tokens[<span class="string">&quot;input_ids&quot;</span>],</span><br><span class="line">        <span class="string">&quot;attention_mask&quot;</span>: tokens[<span class="string">&quot;attention_mask&quot;</span>],</span><br><span class="line">        <span class="string">&quot;labels&quot;</span>: tokens[<span class="string">&quot;input_ids&quot;</span>].copy(),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;åº”ç”¨åˆ†è¯å™¨...&quot;</span>)</span><br><span class="line">train_data = train_data.<span class="built_in">map</span>(</span><br><span class="line">    tokenize_function,</span><br><span class="line">    batched=<span class="literal">False</span>,</span><br><span class="line">    remove_columns=[<span class="string">&quot;text&quot;</span>, <span class="string">&quot;instruction&quot;</span>, <span class="string">&quot;input&quot;</span>, <span class="string">&quot;output&quot;</span>]</span><br><span class="line">)</span><br><span class="line">val_data = val_data.<span class="built_in">map</span>(</span><br><span class="line">    tokenize_function,</span><br><span class="line">    batched=<span class="literal">False</span>,</span><br><span class="line">    remove_columns=[<span class="string">&quot;text&quot;</span>, <span class="string">&quot;instruction&quot;</span>, <span class="string">&quot;input&quot;</span>, <span class="string">&quot;output&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = prepare_model_for_kbit_training(model)</span><br><span class="line"></span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    r=LORA_R,</span><br><span class="line">    lora_alpha=LORA_ALPHA,</span><br><span class="line">    lora_dropout=LORA_DROPOUT,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">    target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = get_peft_model(model, lora_config)</span><br><span class="line">model.print_trainable_parameters()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 4. è®­ç»ƒå‚æ•°</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=OUTPUT_DIR,</span><br><span class="line">    per_device_train_batch_size=<span class="number">1</span>,          <span class="comment"># âœ… å• batchï¼Œé™ä½æ˜¾å­˜</span></span><br><span class="line">    gradient_accumulation_steps=<span class="number">8</span>,          <span class="comment"># âœ… æ¢¯åº¦ç´¯ç§¯å¼¥è¡¥å° batch</span></span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    logging_steps=<span class="number">20</span>,</span><br><span class="line">    save_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    fp16=<span class="literal">True</span>,</span><br><span class="line">    optim=<span class="string">&quot;paged_adamw_8bit&quot;</span>,</span><br><span class="line">    report_to=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    remove_unused_columns=<span class="literal">False</span>,</span><br><span class="line">    gradient_checkpointing=<span class="literal">False</span>,           <span class="comment"># âœ… å…³é—­ä»¥é¿å…è¿‡åº¦æ˜¾å­˜å ç”¨</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 5. å¯åŠ¨è®­ç»ƒ</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=train_data,</span><br><span class="line">    eval_dataset=val_data,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br><span class="line"></span><br><span class="line">trainer.model.save_pretrained(OUTPUT_DIR)</span><br><span class="line">tokenizer.save_pretrained(OUTPUT_DIR)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nğŸ‰ å¾®è°ƒå®Œæˆï¼æ¨¡å‹ä¸LoRAæƒé‡å·²ä¿å­˜åˆ°&quot;</span>, OUTPUT_DIR)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<p><code>3_inference.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- é…ç½®å‚æ•° (è¯·ç¡®ä¿ä¸è®­ç»ƒæ—¶çš„é…ç½®ä¸€è‡´) ---</span></span><br><span class="line"><span class="comment"># åŸºç¡€æ¨¡å‹ï¼ˆQwen/Qwen1.5-1.8B-Chatï¼‰</span></span><br><span class="line">BASE_MODEL = <span class="string">&quot;Qwen/Qwen1.5-1.8B-Chat&quot;</span></span><br><span class="line"><span class="comment"># è®­ç»ƒç»“æœä¿å­˜ç›®å½•ï¼ˆLoRA æƒé‡ï¼‰</span></span><br><span class="line">OUTPUT_DIR = <span class="string">&quot;./qwen1.5_1.8b_lora&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 1. æ¨¡å‹åŠ è½½é…ç½®</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4-bit é‡åŒ–é…ç½®ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰</span></span><br><span class="line">bnb_config = BitsAndBytesConfig(</span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">    bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>,</span><br><span class="line">    bnb_4bit_compute_dtype=torch.float16,</span><br><span class="line">    bnb_4bit_use_double_quant=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸¥æ ¼é™åˆ¶ VRAM å ç”¨</span></span><br><span class="line">MAX_VRAM_GB = <span class="number">5.5</span></span><br><span class="line">max_memory = &#123;</span><br><span class="line">    <span class="number">0</span>: <span class="string">f&#x27;<span class="subst">&#123;<span class="built_in">int</span>(MAX_VRAM_GB * <span class="number">1024</span>)&#125;</span>MiB&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cpu&#x27;</span>: <span class="string">&#x27;30GiB&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;æ­£åœ¨åŠ è½½åŸºç¡€æ¨¡å‹: <span class="subst">&#123;BASE_MODEL&#125;</span>...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. åŠ è½½åŸºç¡€æ¨¡å‹ï¼ˆå¸¦é‡åŒ–ï¼‰</span></span><br><span class="line"><span class="comment"># æ³¨æ„ï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU å†…å­˜</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    BASE_MODEL,</span><br><span class="line">    quantization_config=bnb_config,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    max_memory=max_memory,</span><br><span class="line">    low_cpu_mem_usage=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. åŠ è½½ LoRA é€‚é…å™¨æƒé‡</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;æ­£åœ¨åŠ è½½ LoRA æƒé‡: <span class="subst">&#123;OUTPUT_DIR&#125;</span>...&quot;</span>)</span><br><span class="line">model = PeftModel.from_pretrained(model, OUTPUT_DIR)</span><br><span class="line">model.<span class="built_in">eval</span>() <span class="comment"># åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. åŠ è½½åˆ†è¯å™¨</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;æ¨¡å‹å’Œ LoRA æƒé‡åŠ è½½å®Œæˆã€‚&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 2. æ¨ç†/æµ‹è¯•å‡½æ•°</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_response</span>(<span class="params">instruction, input_text=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    æ ¹æ®æŒ‡ä»¤å’Œè¾“å…¥ç”Ÿæˆæ¨¡å‹çš„å“åº”ã€‚</span></span><br><span class="line"><span class="string">    è¯·ç¡®ä¿ prompt æ ¼å¼ä¸è®­ç»ƒæ—¶ä½¿ç”¨çš„ `format_prompt` ä¸€è‡´ã€‚</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># !!! è­¦å‘Šï¼šè¯·æ£€æŸ¥å¹¶ä¿®æ”¹ Qwen æ¨¡å‹å®é™…ä½¿ç”¨çš„ Prompt æ ¼å¼ !!!</span></span><br><span class="line">    <span class="comment"># å½“å‰æ ¼å¼: </span></span><br><span class="line">    prompt = <span class="string">f&quot;### Instruction:\n<span class="subst">&#123;instruction&#125;</span>\n\n### Input:\n<span class="subst">&#123;input_text&#125;</span>\n\n### Response:\n&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ç¼–ç è¾“å…¥</span></span><br><span class="line">    <span class="comment"># å‡è®¾ CUDA å¯ç”¨</span></span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    inputs = tokenizer(prompt, return_tensors=<span class="string">&quot;pt&quot;</span>, truncation=<span class="literal">True</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ç”Ÿæˆè®¾ç½®</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = model.generate(</span><br><span class="line">            **inputs,</span><br><span class="line">            max_new_tokens=<span class="number">256</span>,         <span class="comment"># æœ€å¤§ç”Ÿæˆé•¿åº¦</span></span><br><span class="line">            do_sample=<span class="literal">True</span>,             <span class="comment"># å¯ç”¨é‡‡æ ·ï¼ˆæ›´è‡ªç„¶çš„æ–‡æœ¬ï¼‰</span></span><br><span class="line">            top_p=<span class="number">0.9</span>,                  <span class="comment"># Top-p é‡‡æ ·</span></span><br><span class="line">            temperature=<span class="number">0.7</span>,            <span class="comment"># æ¸©åº¦</span></span><br><span class="line">            pad_token_id=tokenizer.eos_token_id </span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è§£ç ç»“æœå¹¶æ¸…ç†</span></span><br><span class="line">    response_text = tokenizer.decode(outputs[<span class="number">0</span>], skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># æå–å®é™…çš„ Response éƒ¨åˆ†</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># æ‰¾åˆ° ### Response: ä¹‹åçš„å†…å®¹</span></span><br><span class="line">        start_index = response_text.index(<span class="string">&quot;### Response:\n&quot;</span>) + <span class="built_in">len</span>(<span class="string">&quot;### Response:\n&quot;</span>)</span><br><span class="line">        response = response_text[start_index:].strip()</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="comment"># å¦‚æœæ¨¡å‹æ²¡æœ‰ä¸¥æ ¼éµå¾ªæ ¼å¼ï¼Œåˆ™è¿”å›æ•´ä¸ªè§£ç ç»“æœ</span></span><br><span class="line">        response = response_text.strip()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 3. äº¤äº’å¼æµ‹è¯•å¾ªç¯</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n--- å¯åŠ¨äº¤äº’å¼æµ‹è¯•ï¼ˆè¾“å…¥ &#x27;exit&#x27; æˆ– &#x27;quit&#x27; ç»“æŸï¼‰ ---&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="comment"># æ¥æ”¶æŒ‡ä»¤</span></span><br><span class="line">    user_instruction = <span class="built_in">input</span>(<span class="string">&quot;\n[è¯·è¾“æŒ‡ä»¤ (æˆ– exit/quit é€€å‡º)]: &quot;</span>).strip()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># æ£€æŸ¥é€€å‡ºæŒ‡ä»¤</span></span><br><span class="line">    <span class="keyword">if</span> user_instruction.lower() <span class="keyword">in</span> [<span class="string">&#x27;exit&#x27;</span>, <span class="string">&#x27;quit&#x27;</span>]:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;--- é€€å‡ºäº¤äº’å¼æµ‹è¯• ---&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># æ¥æ”¶å¯é€‰çš„è¾“å…¥æ–‡æœ¬</span></span><br><span class="line">    user_input = <span class="built_in">input</span>(<span class="string">&quot;[è¯·è¾“ Input æ–‡æœ¬ (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡)]: &quot;</span>).strip()</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--- æ­£åœ¨ç”Ÿæˆå“åº”... ---&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># ç”Ÿæˆå“åº”</span></span><br><span class="line">        response = generate_response(user_instruction, user_input)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># æ‰“å°ç»“æœ</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n**æ¨¡å‹å“åº”:**&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span> * <span class="number">20</span>)</span><br><span class="line">        <span class="built_in">print</span>(response)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span> * <span class="number">20</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n[é”™è¯¯]: åœ¨ç”Ÿæˆå“åº”æ—¶å‘ç”Ÿé”™è¯¯ï¼š<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># å¦‚æœå‡ºç°é”™è¯¯ï¼Œç»§ç»­å¾ªç¯è€Œä¸æ˜¯ç›´æ¥é€€å‡º</span></span><br></pre></td></tr></table></figure>


<p>æ‚¨æå‡ºçš„é—®é¢˜éå¸¸å…³é”®ï¼šå¦‚ä½•å°†ç›®å‰åœ¨ Python è„šæœ¬ä¸­è¿è¡Œçš„æ¨¡å‹ï¼Œè½¬æ¢ä¸ºåƒ Ollama é‚£æ ·ï¼Œå¯ä»¥é€šè¿‡ç½‘ç»œ API ç«¯å£ï¼ˆå¦‚ <code>11434</code>ï¼‰è°ƒç”¨çš„æœåŠ¡ã€‚</p>
<p>å½“å‰æ‚¨ä½¿ç”¨çš„ LoRA æ¨¡å¼å’Œ Ollama çš„åŸç”Ÿä½¿ç”¨æ–¹å¼å­˜åœ¨ä¸€ä¸ªæŠ€æœ¯éšœç¢ï¼Œä½†æˆ‘ä»¬æœ‰å®Œç¾çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<h2 id="ğŸ¯-æ ¸å¿ƒéšœç¢ä¸è§£å†³æ–¹æ¡ˆ"><a href="#ğŸ¯-æ ¸å¿ƒéšœç¢ä¸è§£å†³æ–¹æ¡ˆ" class="headerlink" title="ğŸ¯ æ ¸å¿ƒéšœç¢ä¸è§£å†³æ–¹æ¡ˆ"></a>ğŸ¯ æ ¸å¿ƒéšœç¢ä¸è§£å†³æ–¹æ¡ˆ</h2><table>
<thead>
<tr>
<th align="left">æŠ€æœ¯éšœç¢</th>
<th align="left">è§£å†³æ–¹æ¡ˆ</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>LoRA æ¨¡å¼ï¼š</strong> æ‚¨çš„æ¨¡å‹æ˜¯ <strong>Base Model (4bit é‡åŒ–) + LoRA é€‚é…å™¨</strong> åˆ†ç¦»è¿è¡Œçš„ã€‚</td>
<td align="left"><strong>æ¨¡å‹åˆå¹¶ (Merge)ï¼š</strong> å°† LoRA æƒé‡ä¸åŸºç¡€æ¨¡å‹çš„æƒé‡æ°¸ä¹…åˆå¹¶ï¼Œç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„ã€å¯ä»¥ç›´æ¥åŠ è½½çš„ <strong>å…¨é‡æ¨¡å‹</strong>ã€‚</td>
</tr>
<tr>
<td align="left"><strong>Ollama æ”¯æŒï¼š</strong> Ollama ä¸»è¦è®¾è®¡ç”¨äºåŠ è½½æ ‡å‡†çš„ Hugging Face æˆ– GGUF æ ¼å¼çš„<strong>å…¨é‡æ¨¡å‹</strong>ï¼Œå®ƒä¸ç›´æ¥æ”¯æŒåŠ è½½åˆ†ç¦»çš„ LoRA æƒé‡ã€‚</td>
<td align="left"><strong>éƒ¨ç½²åˆå¹¶åçš„æ¨¡å‹ï¼š</strong> å°†åˆå¹¶åçš„æ¨¡å‹è½¬æ¢æˆ <strong>GGUF æ ¼å¼</strong> æˆ–ç›´æ¥ä½¿ç”¨ <strong>FastAPI&#x2F;Flask æ­å»º API æœåŠ¡</strong>ã€‚</td>
</tr>
</tbody></table>
<hr>
<h2 id="ğŸ› ï¸-æ­¥éª¤ä¸€ï¼šåˆå¹¶-LoRA-é€‚é…å™¨-Merge-and-Unload"><a href="#ğŸ› ï¸-æ­¥éª¤ä¸€ï¼šåˆå¹¶-LoRA-é€‚é…å™¨-Merge-and-Unload" class="headerlink" title="ğŸ› ï¸ æ­¥éª¤ä¸€ï¼šåˆå¹¶ LoRA é€‚é…å™¨ (Merge and Unload)"></a>ğŸ› ï¸ æ­¥éª¤ä¸€ï¼šåˆå¹¶ LoRA é€‚é…å™¨ (Merge and Unload)</h2><p>è¿™æ˜¯å°†æ‚¨çš„å¾®è°ƒæˆæœå›ºåŒ–çš„å…³é”®ä¸€æ­¥ã€‚åˆå¹¶åï¼Œæ‚¨å°†ä¸å†éœ€è¦åŸºç¡€æ¨¡å‹å’Œ LoRA æ–‡ä»¶å¤¹ï¼Œåªéœ€åŠ è½½æ–°çš„åˆå¹¶æ¨¡å‹å³å¯ã€‚</p>
<h3 id="1-åˆ›å»ºåˆå¹¶è„šæœ¬-4-merge-model-py"><a href="#1-åˆ›å»ºåˆå¹¶è„šæœ¬-4-merge-model-py" class="headerlink" title="1. åˆ›å»ºåˆå¹¶è„šæœ¬ (4_merge_model.py)"></a>1. åˆ›å»ºåˆå¹¶è„šæœ¬ (<code>4_merge_model.py</code>)</h3><p>è¯·åœ¨æ‚¨çš„é¡¹ç›®ç›®å½•ä¸‹åˆ›å»º <code>4_merge_model.py</code> æ–‡ä»¶ï¼Œå†…å®¹å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- é…ç½®å‚æ•° (è¯·ç¡®ä¿ä¸è®­ç»ƒæ—¶çš„é…ç½®ä¸€è‡´) ---</span></span><br><span class="line">BASE_MODEL = <span class="string">&quot;Qwen/Qwen1.5-1.8B-Chat&quot;</span> </span><br><span class="line">LORA_DIR = <span class="string">&quot;./qwen1.5_1.8b_lora&quot;</span> </span><br><span class="line">MERGED_OUTPUT_DIR = <span class="string">&quot;./qwen1.5_1.8b_merged&quot;</span></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;--- 1. æ­£åœ¨åŠ è½½åŸºç¡€æ¨¡å‹: <span class="subst">&#123;BASE_MODEL&#125;</span> (éé‡åŒ–) ---&quot;</span>)</span><br><span class="line"><span class="comment"># âš ï¸ æ³¨æ„ï¼šåˆå¹¶æ—¶éœ€è¦åŠ è½½åŸºç¡€æ¨¡å‹ä¸ºå…¨ç²¾åº¦ (torch.float16)ï¼Œå¦åˆ™ä¼šå¯¼è‡´ç²¾åº¦ä¸¢å¤±ï¼</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    BASE_MODEL,</span><br><span class="line">    torch_dtype=torch.float16,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    low_cpu_mem_usage=<span class="literal">True</span>,</span><br><span class="line">    <span class="comment"># åˆå¹¶æ—¶ä¸éœ€è¦é‡åŒ–é…ç½®</span></span><br><span class="line">)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;--- 2. æ­£åœ¨åŠ è½½ LoRA æƒé‡: <span class="subst">&#123;LORA_DIR&#125;</span> ---&quot;</span>)</span><br><span class="line"><span class="comment"># ä½¿ç”¨ PeftModel åŒ…è£…åŸºç¡€æ¨¡å‹</span></span><br><span class="line">model = PeftModel.from_pretrained(model, LORA_DIR)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;--- 3. æ­£åœ¨æ‰§è¡Œ LoRA æƒé‡åˆå¹¶ (Merge and Unload) ---&quot;</span>)</span><br><span class="line"><span class="comment"># æ ¸å¿ƒæ“ä½œï¼šå°† LoRA æƒé‡åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹çš„æƒé‡ä¸­ï¼Œå¹¶ç§»é™¤ PeftModel åŒ…è£…</span></span><br><span class="line"><span class="comment"># åˆå¹¶åçš„æ¨¡å‹å°†æ˜¯å…¨ç²¾åº¦ (float16)</span></span><br><span class="line">merged_model = model.merge_and_unload()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;--- 4. æ­£åœ¨ä¿å­˜åˆå¹¶åçš„æ¨¡å‹åˆ°: <span class="subst">&#123;MERGED_OUTPUT_DIR&#125;</span> ---&quot;</span>)</span><br><span class="line"><span class="comment"># ä¿å­˜å…¨é‡çš„åˆå¹¶æ¨¡å‹ï¼ˆåŒ…å«æ‰€æœ‰å¾®è°ƒæ•ˆæœï¼‰</span></span><br><span class="line">merged_model.save_pretrained(MERGED_OUTPUT_DIR)</span><br><span class="line">tokenizer.save_pretrained(MERGED_OUTPUT_DIR)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nğŸ‰ æ¨¡å‹åˆå¹¶å®Œæˆï¼ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨è¿™ä¸ªç›®å½•éƒ¨ç½²æ‚¨çš„ä¸“å®¶æ¨¡å‹äº†ã€‚&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;åˆå¹¶åçš„æ¨¡å‹å·²ä¿å­˜åˆ°ï¼š<span class="subst">&#123;MERGED_OUTPUT_DIR&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-è¿è¡Œåˆå¹¶è„šæœ¬"><a href="#2-è¿è¡Œåˆå¹¶è„šæœ¬" class="headerlink" title="2. è¿è¡Œåˆå¹¶è„šæœ¬"></a>2. è¿è¡Œåˆå¹¶è„šæœ¬</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\zhaoz\Desktop\å¤§æ¨¡å‹è®­ç»ƒ&gt; &amp; C:/Users/zhaoz/anaconda3/python.exe c:/Users/zhaoz/Desktop/å¤§æ¨¡å‹è®­ç»ƒ/<span class="number">4</span>_merge_model.py</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="ğŸš€-æ­¥éª¤äºŒï¼šéƒ¨ç½²åˆå¹¶åçš„æ¨¡å‹-å®ç°-Ollama-Like-è°ƒç”¨"><a href="#ğŸš€-æ­¥éª¤äºŒï¼šéƒ¨ç½²åˆå¹¶åçš„æ¨¡å‹-å®ç°-Ollama-Like-è°ƒç”¨" class="headerlink" title="ğŸš€ æ­¥éª¤äºŒï¼šéƒ¨ç½²åˆå¹¶åçš„æ¨¡å‹ (å®ç° Ollama-Like è°ƒç”¨)"></a>ğŸš€ æ­¥éª¤äºŒï¼šéƒ¨ç½²åˆå¹¶åçš„æ¨¡å‹ (å®ç° Ollama-Like è°ƒç”¨)</h2><p>åˆå¹¶å®Œæˆåï¼Œæ‚¨æœ‰ä¸¤ç§ä¸»æµçš„éƒ¨ç½²æ–¹å¼æ¥æä¾› API æœåŠ¡ï¼š</p>
<h3 id="é€‰é¡¹-Aï¼šä½¿ç”¨-Hugging-Face-transformers-æ­å»º-API-æ¨è"><a href="#é€‰é¡¹-Aï¼šä½¿ç”¨-Hugging-Face-transformers-æ­å»º-API-æ¨è" class="headerlink" title="é€‰é¡¹ Aï¼šä½¿ç”¨ Hugging Face transformers æ­å»º API (æ¨è)"></a>é€‰é¡¹ Aï¼šä½¿ç”¨ Hugging Face <code>transformers</code> æ­å»º API (æ¨è)</h3><p>è¿™æ˜¯æœ€ç›´æ¥ã€æœ€çµæ´»çš„æ–¹å¼ï¼Œå¯ä»¥å®Œç¾æ¨¡æ‹Ÿ Ollama çš„ API æ¥å£ã€‚</p>
<ol>
<li><p><strong>å®‰è£…ä¾èµ–ï¼š</strong> éœ€è¦å®‰è£… <code>FastAPI</code> å’Œ <code>uvicorn</code> æ¥æ­å»º Web æœåŠ¡ã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install fastapi uvicorn</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>åˆ›å»º API è„šæœ¬ (<code>5_api_server.py</code>):</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, HTTPException</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- é…ç½®å‚æ•° ---</span></span><br><span class="line">MERGED_OUTPUT_DIR = <span class="string">&quot;./qwen1.5_1.8b_merged&quot;</span></span><br><span class="line"><span class="comment"># ------------------</span></span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Fine-tuned LLM API&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># é¢„ç•™ç»™æ¨¡å‹çš„å…¨å±€å˜é‡</span></span><br><span class="line">model = <span class="literal">None</span></span><br><span class="line">tokenizer = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰è¯·æ±‚ä½“çš„æ•°æ®ç»“æ„</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GenerationRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    instruction: <span class="built_in">str</span></span><br><span class="line">    input_text: <span class="built_in">str</span> = <span class="string">&quot;&quot;</span></span><br><span class="line">    max_new_tokens: <span class="built_in">int</span> = <span class="number">256</span></span><br><span class="line">    temperature: <span class="built_in">float</span> = <span class="number">0.7</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.on_event(<span class="params"><span class="string">&quot;startup&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_model</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;FastAPI å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">global</span> model, tokenizer</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;--- API å¯åŠ¨ä¸­ï¼šæ­£åœ¨åŠ è½½åˆå¹¶åçš„æ¨¡å‹ ---&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ä½¿ç”¨ float16 èŠ‚çœæ˜¾å­˜ï¼Œå¹¶åŠ è½½åˆ° GPU</span></span><br><span class="line">        model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">            MERGED_OUTPUT_DIR,</span><br><span class="line">            torch_dtype=torch.float16,</span><br><span class="line">            device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">        )</span><br><span class="line">        tokenizer = AutoTokenizer.from_pretrained(MERGED_OUTPUT_DIR)</span><br><span class="line">        tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;--- æ¨¡å‹åŠ è½½æˆåŠŸï¼API æœåŠ¡å·²å‡†å¤‡å°±ç»ª ---&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;æ¨¡å‹åŠ è½½å¤±è´¥: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">500</span>, detail=<span class="string">&quot;æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ˜¾å­˜ã€‚&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">format_prompt</span>(<span class="params">instruction, input_text</span>):</span><br><span class="line">    <span class="comment"># å¿…é¡»ä¸è®­ç»ƒæ—¶çš„æ ¼å¼å®Œå…¨ä¸€è‡´</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;### Instruction:\n<span class="subst">&#123;instruction&#125;</span>\n\n### Input:\n<span class="subst">&#123;input_text&#125;</span>\n\n### Response:\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/generate&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_endpoint</span>(<span class="params">request: GenerationRequest</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;API æ ¸å¿ƒæ¨ç†ç«¯ç‚¹&quot;&quot;&quot;</span></span><br><span class="line">    prompt = format_prompt(request.instruction, request.input_text)</span><br><span class="line">    </span><br><span class="line">    inputs = tokenizer(prompt, return_tensors=<span class="string">&quot;pt&quot;</span>, truncation=<span class="literal">True</span>).to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = model.generate(</span><br><span class="line">            **inputs,</span><br><span class="line">            max_new_tokens=request.max_new_tokens,</span><br><span class="line">            temperature=request.temperature,</span><br><span class="line">            do_sample=<span class="literal">True</span>,</span><br><span class="line">            pad_token_id=tokenizer.eos_token_id,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    response_text = tokenizer.decode(outputs[<span class="number">0</span>], skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># æå– Response éƒ¨åˆ† (ä¸ 3_inference.py é€»è¾‘ç›¸åŒ)</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        start_index = response_text.index(<span class="string">&quot;### Response:\n&quot;</span>) + <span class="built_in">len</span>(<span class="string">&quot;### Response:\n&quot;</span>)</span><br><span class="line">        response = response_text[start_index:].strip()</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        response = response_text.strip() <span class="comment"># å›é€€åˆ°å®Œæ•´è¾“å‡º</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;response&quot;</span>: response, <span class="string">&quot;model_id&quot;</span>: MERGED_OUTPUT_DIR&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯åŠ¨æœåŠ¡å™¨ (åœ¨è„šæœ¬æœ«å°¾æ·»åŠ ï¼Œæ³¨æ„ï¼šuvicorn è¿è¡Œæ—¶ç«¯å£æ˜¯ 8000)</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># åœ¨ PowerShell ä¸­ï¼Œè¿è¡Œæ­¤å‘½ä»¤</span></span><br><span class="line">    <span class="comment"># uvicorn 5_api_server:app --host 0.0.0.0 --port 8000</span></span><br><span class="line">    <span class="comment"># å¦‚æœä½ æƒ³ä½¿ç”¨ 11434 ç«¯å£ï¼Œæ”¹æˆ --port 11434</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nè¯·åœ¨ç»ˆç«¯è¿è¡Œï¼šuvicorn 5_api_server:app --host 0.0.0.0 --port 11434&quot;</span>)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>è¿è¡Œ API æœåŠ¡ï¼š</strong></p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\zhaoz\Desktop\å¤§æ¨¡å‹è®­ç»ƒ&gt; uvicorn <span class="number">5</span>_api_server:app <span class="literal">--host</span> <span class="number">0.0</span>.<span class="number">0.0</span> <span class="literal">--port</span> <span class="number">11434</span></span><br></pre></td></tr></table></figure>

<p>ç°åœ¨ï¼Œæ‚¨çš„æ¨¡å‹å°±åœ¨ <code>http://127.0.0.1:11434/generate</code> ä¸Šæä¾›æœåŠ¡äº†ï¼æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•ç¼–ç¨‹è¯­è¨€æˆ–å·¥å…·å‘è¯¥åœ°å€å‘é€ POST è¯·æ±‚è¿›è¡Œè°ƒç”¨ã€‚</p>
</li>
</ol>
<h3 id="é€‰é¡¹-Bï¼šå°†æ¨¡å‹å¯¼å…¥åˆ°-Ollama-å¦‚æœåšæŒä½¿ç”¨-Ollama"><a href="#é€‰é¡¹-Bï¼šå°†æ¨¡å‹å¯¼å…¥åˆ°-Ollama-å¦‚æœåšæŒä½¿ç”¨-Ollama" class="headerlink" title="é€‰é¡¹ Bï¼šå°†æ¨¡å‹å¯¼å…¥åˆ° Ollama (å¦‚æœåšæŒä½¿ç”¨ Ollama)"></a>é€‰é¡¹ Bï¼šå°†æ¨¡å‹å¯¼å…¥åˆ° Ollama (å¦‚æœåšæŒä½¿ç”¨ Ollama)</h3><p>å¦‚æœæ‚¨å¸Œæœ›åœ¨ Ollama å®¢æˆ·ç«¯ä¸­ç®¡ç†å’Œè¿è¡Œæ­¤æ¨¡å‹ï¼Œå¯ä»¥é‡‡ç”¨ä»¥ä¸‹æµç¨‹ï¼š</p>
<ol>
<li><strong>è½¬æ¢åˆ° GGUF æ ¼å¼ï¼š</strong> Ollama æœ€å¥½ä½¿ç”¨ GGUF æ ¼å¼çš„æ¨¡å‹ã€‚æ‚¨éœ€è¦ä½¿ç”¨ <code>llama.cpp</code> å·¥å…·é“¾å°†åˆå¹¶åçš„ Safetensors æ¨¡å‹è½¬æ¢æˆ GGUFã€‚è¿™ä¸ªè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å®‰è£…é¢å¤–çš„ç¼–è¯‘å·¥å…·å’Œä¾èµ–ã€‚</li>
<li><strong>åˆ›å»º Modelfileï¼š</strong> åœ¨ Ollama ä¸­ï¼Œæ‚¨éœ€è¦åˆ›å»ºä¸€ä¸ª <code>Modelfile</code> æ¥æŒ‡å‘æ‚¨è½¬æ¢çš„ GGUF æ–‡ä»¶ï¼Œå¹¶å®šä¹‰æ‚¨çš„ Chat Prompt æ¨¡æ¿ï¼Œç¡®ä¿ Prompt æ¨¡æ¿ä¸è®­ç»ƒæ—¶çš„æ ¼å¼ä¸€è‡´ï¼ˆ<code>### Instruction:\n...\n\n### Response:\n</code>ï¼‰ã€‚</li>
<li><strong>å¯¼å…¥ Ollamaï¼š</strong> ä½¿ç”¨ <code>ollama create your_expert_model -f ./Modelfile</code> å‘½ä»¤å°†æ¨¡å‹å¯¼å…¥ Ollamaã€‚</li>
</ol>
<p><strong>æ¨èï¼š</strong> å¯¹äºåˆå­¦è€…å’Œéœ€è¦çµæ´»æ§åˆ¶ API çš„åœºæ™¯ï¼Œ<strong>é€‰é¡¹ A</strong>ï¼ˆFastAPI&#x2F;Uvicornï¼‰æ˜¯æ›´å¿«é€Ÿã€æ›´ç›´æ¥çš„è§£å†³æ–¹æ¡ˆï¼Œå®ƒèƒ½è®©æ‚¨å³åˆ»è·å¾—ä¸€ä¸ªç±»ä¼¼äº Ollama çš„ API è°ƒç”¨ä½“éªŒã€‚</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/Cherises/">Leonardo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://cherises.github.io/post/2522/">https://cherises.github.io/post/2522/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://github.com/Cherises/">Leonardo</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="https://raw.githubusercontent.com/Cherises/Blog-Resource-2/refs/heads/main/photos/genshin/emoj/569.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/actor-1.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Leonardo</div><div class="author-info-description">Focus on thinking, imagination, reasoning, truth-seeking, and pragmatism</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">108</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">149</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">23</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Cherises/"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%9A%80-%E4%BB%8E-0-%E5%88%B0-1%EF%BC%9A%E5%9F%BA%E4%BA%8E-QLoRA-%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E8%80%83%E8%AF%95%E9%A2%98%E5%BA%93-AI-%E4%B8%93%E5%AE%B6"><span class="toc-number">1.</span> <span class="toc-text">ğŸš€ ä» 0 åˆ° 1ï¼šåŸºäº QLoRA å¾®è°ƒä½ çš„ç¬¬ä¸€ä¸ªè€ƒè¯•é¢˜åº“ AI ä¸“å®¶</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E4%B8%80%E3%80%81%E9%A1%B9%E7%9B%AE%E7%9B%AE%E6%A0%87%E4%B8%8E%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B"><span class="toc-number">1.1.</span> <span class="toc-text">ğŸ¯ ä¸€ã€é¡¹ç›®ç›®æ ‡ä¸æŠ€æœ¯é€‰å‹</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%9B%AE%E6%A0%87"><span class="toc-number">1.1.1.</span> <span class="toc-text">1. ç›®æ ‡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B"><span class="toc-number">1.1.2.</span> <span class="toc-text">2. æŠ€æœ¯é€‰å‹</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9B%A0%EF%B8%8F-%E4%BA%8C%E3%80%81%E7%8E%AF%E5%A2%83%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">1.2.</span> <span class="toc-text">ğŸ› ï¸ äºŒã€ç¯å¢ƒä¸æ•°æ®å‡†å¤‡</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.1.</span> <span class="toc-text">1. åŸºç¡€ç¯å¢ƒé…ç½®</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E5%8C%96-1-data-prep-py"><span class="toc-number">1.2.2.</span> <span class="toc-text">2. æ•°æ®æ ¼å¼åŒ– (1_data_prep.py)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9A%99%EF%B8%8F-%E4%B8%89%E3%80%81QLoRA-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83-2-qlora-finetune-py"><span class="toc-number">1.3.</span> <span class="toc-text">âš™ï¸ ä¸‰ã€QLoRA æ¨¡å‹å¾®è°ƒ (2_qlora_finetune.py)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-QLoRA-%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE"><span class="toc-number">1.3.1.</span> <span class="toc-text">1. QLoRA æ ¸å¿ƒé…ç½®</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%AE%AD%E7%BB%83%E8%84%9A%E6%9C%AC-2-qlora-finetune-py-%E8%BF%90%E8%A1%8C"><span class="toc-number">1.3.2.</span> <span class="toc-text">2. è®­ç»ƒè„šæœ¬ (2_qlora_finetune.py) è¿è¡Œ</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%AA-%E5%9B%9B%E3%80%81%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E4%B8%8E%E6%95%88%E6%9E%9C%E6%B5%8B%E8%AF%95-3-inference-py"><span class="toc-number">1.4.</span> <span class="toc-text">ğŸ§ª å››ã€æ¨¡å‹è°ƒç”¨ä¸æ•ˆæœæµ‹è¯• (3_inference.py)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A0%B8%E5%BF%83%E8%B0%83%E7%94%A8%E9%80%BB%E8%BE%91"><span class="toc-number">1.4.1.</span> <span class="toc-text">1. æ ¸å¿ƒè°ƒç”¨é€»è¾‘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%88%E6%9E%9C%E6%B5%8B%E8%AF%95%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.4.2.</span> <span class="toc-text">2. æ•ˆæœæµ‹è¯•ç¤ºä¾‹</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%92%A1-%E4%BA%94%E3%80%81%E6%80%BB%E7%BB%93%E4%B8%8E%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A"><span class="toc-number">1.5.</span> <span class="toc-text">ğŸ’¡ äº”ã€æ€»ç»“ä¸å¿ƒå¾—ä½“ä¼š</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#QLoRA-%E5%BE%AE%E8%B0%83%E7%9A%84%E7%9C%9F%E6%AD%A3%E4%BB%B7%E5%80%BC"><span class="toc-number">1.5.1.</span> <span class="toc-text">QLoRA å¾®è°ƒçš„çœŸæ­£ä»·å€¼</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93"><span class="toc-number">1.5.2.</span> <span class="toc-text">ç»éªŒæ€»ç»“</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%A0%B8%E5%BF%83%E9%9A%9C%E7%A2%8D%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">1.6.</span> <span class="toc-text">ğŸ¯ æ ¸å¿ƒéšœç¢ä¸è§£å†³æ–¹æ¡ˆ</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9B%A0%EF%B8%8F-%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%90%88%E5%B9%B6-LoRA-%E9%80%82%E9%85%8D%E5%99%A8-Merge-and-Unload"><span class="toc-number">1.7.</span> <span class="toc-text">ğŸ› ï¸ æ­¥éª¤ä¸€ï¼šåˆå¹¶ LoRA é€‚é…å™¨ (Merge and Unload)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%9B%E5%BB%BA%E5%90%88%E5%B9%B6%E8%84%9A%E6%9C%AC-4-merge-model-py"><span class="toc-number">1.7.1.</span> <span class="toc-text">1. åˆ›å»ºåˆå¹¶è„šæœ¬ (4_merge_model.py)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%BF%90%E8%A1%8C%E5%90%88%E5%B9%B6%E8%84%9A%E6%9C%AC"><span class="toc-number">1.7.2.</span> <span class="toc-text">2. è¿è¡Œåˆå¹¶è„šæœ¬</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E9%83%A8%E7%BD%B2%E5%90%88%E5%B9%B6%E5%90%8E%E7%9A%84%E6%A8%A1%E5%9E%8B-%E5%AE%9E%E7%8E%B0-Ollama-Like-%E8%B0%83%E7%94%A8"><span class="toc-number">1.8.</span> <span class="toc-text">ğŸš€ æ­¥éª¤äºŒï¼šéƒ¨ç½²åˆå¹¶åçš„æ¨¡å‹ (å®ç° Ollama-Like è°ƒç”¨)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%89%E9%A1%B9-A%EF%BC%9A%E4%BD%BF%E7%94%A8-Hugging-Face-transformers-%E6%90%AD%E5%BB%BA-API-%E6%8E%A8%E8%8D%90"><span class="toc-number">1.8.1.</span> <span class="toc-text">é€‰é¡¹ Aï¼šä½¿ç”¨ Hugging Face transformers æ­å»º API (æ¨è)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%89%E9%A1%B9-B%EF%BC%9A%E5%B0%86%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%85%A5%E5%88%B0-Ollama-%E5%A6%82%E6%9E%9C%E5%9D%9A%E6%8C%81%E4%BD%BF%E7%94%A8-Ollama"><span class="toc-number">1.8.2.</span> <span class="toc-text">é€‰é¡¹ Bï¼šå°†æ¨¡å‹å¯¼å…¥åˆ° Ollama (å¦‚æœåšæŒä½¿ç”¨ Ollama)</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/57079/" title="å…³äºäºŒæ¬¡å…ƒçš„åˆ†ææŠ¥å‘Š"><img src="https://raw.githubusercontent.com/Cherises/Blog-Resource-2/refs/heads/main/photos/genshin/emoj/658.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="å…³äºäºŒæ¬¡å…ƒçš„åˆ†ææŠ¥å‘Š"/></a><div class="content"><a class="title" href="/post/57079/" title="å…³äºäºŒæ¬¡å…ƒçš„åˆ†ææŠ¥å‘Š">å…³äºäºŒæ¬¡å…ƒçš„åˆ†ææŠ¥å‘Š</a><time datetime="2025-12-07T21:46:37.000Z" title="Created 2025-12-07 21:46:37">2025-12-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/14858/" title="2025å¹´11æœˆ30æ—¥ç½‘æ˜“æ–°é—»æ”¶å½•"><img src="https://raw.githubusercontent.com/Cherises/Blog-Resource-2/refs/heads/main/photos/genshin/emoj/471.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2025å¹´11æœˆ30æ—¥ç½‘æ˜“æ–°é—»æ”¶å½•"/></a><div class="content"><a class="title" href="/post/14858/" title="2025å¹´11æœˆ30æ—¥ç½‘æ˜“æ–°é—»æ”¶å½•">2025å¹´11æœˆ30æ—¥ç½‘æ˜“æ–°é—»æ”¶å½•</a><time datetime="2025-11-30T19:44:30.000Z" title="Created 2025-11-30 19:44:30">2025-11-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/250/" title="é—ºèœœå…³ç³»åˆ†ææŠ¥å‘Š"><img src="https://raw.githubusercontent.com/Cherises/Blog-Resource-2/refs/heads/main/photos/genshin/emoj/178.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="é—ºèœœå…³ç³»åˆ†ææŠ¥å‘Š"/></a><div class="content"><a class="title" href="/post/250/" title="é—ºèœœå…³ç³»åˆ†ææŠ¥å‘Š">é—ºèœœå…³ç³»åˆ†ææŠ¥å‘Š</a><time datetime="2025-11-29T19:24:00.000Z" title="Created 2025-11-29 19:24:00">2025-11-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/30270/" title="å…³äºäººæ€§åˆ«ä¹‹é—´çš„å·®å¼‚"><img src="https://raw.githubusercontent.com/Cherises/Blog-Resource-2/refs/heads/main/photos/genshin/emoj/150.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="å…³äºäººæ€§åˆ«ä¹‹é—´çš„å·®å¼‚"/></a><div class="content"><a class="title" href="/post/30270/" title="å…³äºäººæ€§åˆ«ä¹‹é—´çš„å·®å¼‚">å…³äºäººæ€§åˆ«ä¹‹é—´çš„å·®å¼‚</a><time datetime="2025-11-27T08:46:25.000Z" title="Created 2025-11-27 08:46:25">2025-11-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/37181/" title="è·å–æ–°é—»åˆ—è¡¨å¹¶è°ƒç”¨å¤§æ¨¡å‹æ€»ç»“"><img src="https://raw.githubusercontent.com/Cherises/Blog-Resource-2/refs/heads/main/photos/genshin/emoj/625.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="è·å–æ–°é—»åˆ—è¡¨å¹¶è°ƒç”¨å¤§æ¨¡å‹æ€»ç»“"/></a><div class="content"><a class="title" href="/post/37181/" title="è·å–æ–°é—»åˆ—è¡¨å¹¶è°ƒç”¨å¤§æ¨¡å‹æ€»ç»“">è·å–æ–°é—»åˆ—è¡¨å¹¶è°ƒç”¨å¤§æ¨¡å‹æ€»ç»“</a><time datetime="2025-11-16T17:20:17.000Z" title="Created 2025-11-16 17:20:17">2025-11-16</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2021 - 2026 By Leonardo</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"></div><script src="/js/scroll-disable-blur.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script>(() => {
  const destroyAplayer = () => {
    if (window.aplayers) {
      for (let i = 0; i < window.aplayers.length; i++) {
        if (!window.aplayers[i].options.fixed) {
          window.aplayers[i].destroy()
        }
      }
    }
  }

  const runMetingJS = () => {
    typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()
  }

  btf.addGlobalFn('pjaxSend', destroyAplayer, 'destroyAplayer')
  btf.addGlobalFn('pjaxComplete', loadMeting, 'runMetingJS')
})()</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      false
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« ğŸ”" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>