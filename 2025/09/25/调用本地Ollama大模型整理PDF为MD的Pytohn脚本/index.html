<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>调用本地Ollama大模型整理PDF为MD的Pytohn脚本 | Leo's Digital Genesis</title><meta name="author" content="Leonardo"><meta name="copyright" content="Leonardo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前情提要：我的本地有一些PDF文档，我想整理成为md格式的，但是一次发给大模型肯定会很多，于是想着先写个脚本，把pdf转为txt，然后把txt分块给大模型整理成md，最后合并成为完整的md文档，以下是代码。  1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515">
<meta property="og:type" content="article">
<meta property="og:title" content="调用本地Ollama大模型整理PDF为MD的Pytohn脚本">
<meta property="og:url" content="https://cherises.github.io/2025/09/25/%E8%B0%83%E7%94%A8%E6%9C%AC%E5%9C%B0Ollama%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%95%B4%E7%90%86PDF%E4%B8%BAMD%E7%9A%84Pytohn%E8%84%9A%E6%9C%AC/index.html">
<meta property="og:site_name" content="Leo&#39;s Digital Genesis">
<meta property="og:description" content="前情提要：我的本地有一些PDF文档，我想整理成为md格式的，但是一次发给大模型肯定会很多，于是想着先写个脚本，把pdf转为txt，然后把txt分块给大模型整理成md，最后合并成为完整的md文档，以下是代码。  1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cherises.github.io/img/actor-1.jpg">
<meta property="article:published_time" content="2025-09-25T10:21:30.000Z">
<meta property="article:modified_time" content="2025-09-25T02:23:54.121Z">
<meta property="article:author" content="Leonardo">
<meta property="article:tag" content="Ollama">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="脚本">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cherises.github.io/img/actor-1.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "调用本地Ollama大模型整理PDF为MD的Pytohn脚本",
  "url": "https://cherises.github.io/2025/09/25/%E8%B0%83%E7%94%A8%E6%9C%AC%E5%9C%B0Ollama%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%95%B4%E7%90%86PDF%E4%B8%BAMD%E7%9A%84Pytohn%E8%84%9A%E6%9C%AC/",
  "image": "https://cherises.github.io/img/actor-1.jpg",
  "datePublished": "2025-09-25T10:21:30.000Z",
  "dateModified": "2025-09-25T02:23:54.121Z",
  "author": [
    {
      "@type": "Person",
      "name": "Leonardo",
      "url": "https://github.com/Cherises/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://cherises.github.io/2025/09/25/%E8%B0%83%E7%94%A8%E6%9C%AC%E5%9C%B0Ollama%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%95%B4%E7%90%86PDF%E4%B8%BAMD%E7%9A%84Pytohn%E8%84%9A%E6%9C%AC/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":5,"unescape":false,"languages":{"hits_empty":"No results found for: ${query}","hits_stats":"${hits} articles found"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '调用本地Ollama大模型整理PDF为MD的Pytohn脚本',
  isHighlightShrink: false,
  isToc: false,
  pageType: 'post'
}</script><style> /* 调整全局APlayer位置 */ #global-aplayer.aplayer-fixed { z-index: 9999;           /* 保证在Live2D之上或之下 */ } </style><meta name="generator" content="Hexo 7.3.0"></head><body><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/actor-1.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">56</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">59</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">5</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/Gallery"><i class="fa-fw fas fa-home"></i><span> Gallery</span></a></div><div class="menus_item"><a class="site-page" href="/Wujie/"><i class="fa-fw fas fa-globe"></i><span> 物界</span></a></div><div class="menus_item"><a class="site-page" href="/Music/"><i class="fa-fw fas fa-music"></i><span> 音乐馆</span></a></div><div class="menus_item"><a class="site-page" href="/About/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://raw.githubusercontent.com/Cherises/Blog-Resource/main/photos/banner-top.jpeg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Leo's Digital Genesis</span></a><a class="nav-page-title" href="/"><span class="site-name">调用本地Ollama大模型整理PDF为MD的Pytohn脚本</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/Gallery"><i class="fa-fw fas fa-home"></i><span> Gallery</span></a></div><div class="menus_item"><a class="site-page" href="/Wujie/"><i class="fa-fw fas fa-globe"></i><span> 物界</span></a></div><div class="menus_item"><a class="site-page" href="/Music/"><i class="fa-fw fas fa-music"></i><span> 音乐馆</span></a></div><div class="menus_item"><a class="site-page" href="/About/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">调用本地Ollama大模型整理PDF为MD的Pytohn脚本</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-09-25T10:21:30.000Z" title="Created 2025-09-25 10:21:30">2025-09-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-09-25T02:23:54.121Z" title="Updated 2025-09-25 02:23:54">2025-09-25</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">3.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>21mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><blockquote>
<p>前情提要：我的本地有一些PDF文档，我想整理成为md格式的，但是一次发给大模型肯定会很多，于是想着先写个脚本，把pdf转为txt，然后把txt分块给大模型整理成md，最后合并成为完整的md文档，以下是代码。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">ollama_edit_pipeline.py</span></span><br><span class="line"><span class="string">Single-file pipeline:</span></span><br><span class="line"><span class="string">  1) Extract text from PDF (auto-detect scanned / optionally OCR)</span></span><br><span class="line"><span class="string">  2) Chunk text by characters (smart cut on newline/sentence)</span></span><br><span class="line"><span class="string">  3) For each chunk call Ollama /api/chat with a system prompt that returns JSON:</span></span><br><span class="line"><span class="string">       keys: revised, edits, notes</span></span><br><span class="line"><span class="string">  4) Save per-chunk JSON results, extract &#x27;revised&#x27; and merge to combined.md</span></span><br><span class="line"><span class="string">  5) Optionally run pandoc to convert combined.md -&gt; final.docx</span></span><br><span class="line"><span class="string">  6) Optional: final pass (global style/consistency) by the model</span></span><br><span class="line"><span class="string">  7) Optional: generate embeddings through Ollama embedding model &quot;nomic-embed-text:latest&quot;</span></span><br><span class="line"><span class="string">Usage:</span></span><br><span class="line"><span class="string">  pip install pypdf requests</span></span><br><span class="line"><span class="string">  optional: pip install tqdm</span></span><br><span class="line"><span class="string">  optional system tools: ocrmypdf, pdftotext (poppler), pandoc</span></span><br><span class="line"><span class="string">Example:</span></span><br><span class="line"><span class="string">  python ollama_edit_pipeline.py -i input.pdf -o outdir --model gpt-oss:20b --chunk_chars 16000 --pandoc</span></span><br><span class="line"><span class="string">Notes:</span></span><br><span class="line"><span class="string">  - Ensure ollama server is running (default http://127.0.0.1:11434) and required models are loaded.</span></span><br><span class="line"><span class="string">  - If PDF is scanned, use --ocr to run ocrmypdf (must be installed).</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span>, <span class="type">Any</span>, <span class="type">Dict</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> pypdf <span class="keyword">import</span> PdfReader</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Missing pypdf. Install with: pip install pypdf&quot;</span>)</span><br><span class="line">    <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Missing requests. Install with: pip install requests&quot;</span>)</span><br><span class="line">    <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Optional progress bar</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">    tqdm = <span class="keyword">lambda</span> x, **k: x  <span class="comment"># fallback iterable</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Configurable defaults</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line">DEFAULT_API = <span class="string">&quot;http://127.0.0.1:11434/api/chat&quot;</span></span><br><span class="line">DEFAULT_EMBED_API = <span class="string">&quot;http://127.0.0.1:11434/api/embed&quot;</span>  <span class="comment"># best-effort; may not exist on every Ollama deployment</span></span><br><span class="line">DEFAULT_MODEL = <span class="string">&quot;gpt-oss:20b&quot;</span></span><br><span class="line">DEFAULT_EMBED_MODEL = <span class="string">&quot;nomic-embed-text:latest&quot;</span></span><br><span class="line">DEFAULT_CHUNK_CHARS = <span class="number">16000</span></span><br><span class="line">SYSTEM_PROMPT = (</span><br><span class="line">    <span class="string">&quot;You are a meticulous native-English editor. For the given text chunk:\n&quot;</span></span><br><span class="line">    <span class="string">&quot;1) Produce a corrected, well-flowing version (preserve meaning).\n&quot;</span></span><br><span class="line">    <span class="string">&quot;2) Provide a short edits list: each edit = &#123;loc: \&quot;paragraph x\&quot;, change: \&quot;old -&gt; new\&quot;, why: \&quot;...\&quot;&#125;.\n&quot;</span></span><br><span class="line">    <span class="string">&quot;3) Mention any structural issues (missing headings, repeated sections, bad order).\n&quot;</span></span><br><span class="line">    <span class="string">&quot;4) Output as JSON with keys: revised (markdown), edits (array), notes (string).\n&quot;</span></span><br><span class="line">    <span class="string">&quot;Do NOT add new factual claims, do NOT change citations/references.\n&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Utilities</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_cmd_check</span>(<span class="params">cmd: <span class="type">List</span>[<span class="built_in">str</span>], check: <span class="built_in">bool</span> = <span class="literal">True</span></span>) -&gt; subprocess.CompletedProcess:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Run a shell command and return CompletedProcess.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=<span class="literal">True</span>, check=check)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_executable_available</span>(<span class="params">name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    <span class="keyword">return</span> shutil.which(name) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># PDF extraction</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_text_pypdf</span>(<span class="params">pdf_path: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Extract text from each page using pypdf. Returns list of page texts.&quot;&quot;&quot;</span></span><br><span class="line">    reader = PdfReader(pdf_path)</span><br><span class="line">    pages = []</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> reader.pages:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            text = p.extract_text() <span class="keyword">or</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            text = <span class="string">&quot;&quot;</span></span><br><span class="line">        pages.append(text)</span><br><span class="line">    <span class="keyword">return</span> pages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detect_scanned</span>(<span class="params">pages_texts: <span class="type">List</span>[<span class="built_in">str</span>], threshold_chars_per_page: <span class="built_in">int</span> = <span class="number">50</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return True if extracted text suggests scanned PDF (very few chars per page).&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pages_texts:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    avg = <span class="built_in">sum</span>(<span class="built_in">len</span>(t.strip()) <span class="keyword">for</span> t <span class="keyword">in</span> pages_texts) / <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">len</span>(pages_texts))</span><br><span class="line">    <span class="keyword">return</span> avg &lt; threshold_chars_per_page</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_ocrmypdf</span>(<span class="params">input_pdf: <span class="built_in">str</span>, output_pdf: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Run ocrmypdf to create an OCRed PDF. Requires ocrmypdf installed.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> is_executable_available(<span class="string">&quot;ocrmypdf&quot;</span>):</span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">&quot;ocrmypdf not found. Install it or skip --ocr.&quot;</span>)</span><br><span class="line">    cmd = [<span class="string">&quot;ocrmypdf&quot;</span>, <span class="string">&quot;--rotate-pages&quot;</span>, <span class="string">&quot;--deskew&quot;</span>, input_pdf, output_pdf]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Running OCRmyPDF (this may take a while)...&quot;</span>)</span><br><span class="line">    run_cmd_check(cmd)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pdftotext_to_file</span>(<span class="params">pdf_path: <span class="built_in">str</span>, out_txt_path: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Use pdftotext (poppler) if available for better layout.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> is_executable_available(<span class="string">&quot;pdftotext&quot;</span>):</span><br><span class="line">        <span class="comment"># fallback: use pypdf concatenation</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;pdftotext not available; falling back to pypdf extraction.&quot;</span>)</span><br><span class="line">        pages = extract_text_pypdf(pdf_path)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(out_txt_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&quot;\n\n&quot;</span>.join(pages))</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    cmd = [<span class="string">&quot;pdftotext&quot;</span>, <span class="string">&quot;-layout&quot;</span>, pdf_path, out_txt_path]</span><br><span class="line">    run_cmd_check(cmd)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_text_to_file</span>(<span class="params">pdf_path: <span class="built_in">str</span>, out_txt_path: <span class="built_in">str</span>, use_ocr: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Extract text from PDF and write to out_txt_path.</span></span><br><span class="line"><span class="string">    If use_ocr True, try ocrmypdf first when detection suggests scanning.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    pages = extract_text_pypdf(pdf_path)</span><br><span class="line">    scanned = detect_scanned(pages)</span><br><span class="line">    <span class="keyword">if</span> scanned <span class="keyword">and</span> use_ocr:</span><br><span class="line">        tmp_ocr_pdf = out_txt_path + <span class="string">&quot;.ocr.pdf&quot;</span></span><br><span class="line">        run_ocrmypdf(pdf_path, tmp_ocr_pdf)</span><br><span class="line">        <span class="comment"># try pdftotext from the OCRed pdf</span></span><br><span class="line">        pdftotext_to_file(tmp_ocr_pdf, out_txt_path)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            os.remove(tmp_ocr_pdf)</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># else just write pypdf-extracted</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(out_txt_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(<span class="string">&quot;\n\n&quot;</span>.join(pages))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Chunking</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chunk_text</span>(<span class="params">text: <span class="built_in">str</span>, chunk_chars: <span class="built_in">int</span> = DEFAULT_CHUNK_CHARS</span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Chunk text by character length, trying to end on newline or sentence boundary.</span></span><br><span class="line"><span class="string">    This is the function you provided, improved slightly to also consider sentence punctuation.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    chunks = []</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    L = <span class="built_in">len</span>(text)</span><br><span class="line">    <span class="keyword">while</span> i &lt; L:</span><br><span class="line">        take_to = <span class="built_in">min</span>(i + chunk_chars, L)</span><br><span class="line">        chunk = text[i:take_to]</span><br><span class="line">        <span class="keyword">if</span> take_to &lt; L:</span><br><span class="line">            <span class="comment"># attempt to cut at last newline</span></span><br><span class="line">            cut_candidates = []</span><br><span class="line">            ln = chunk.rfind(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> ln &gt; <span class="number">0</span>:</span><br><span class="line">                cut_candidates.append(ln)</span><br><span class="line">            <span class="comment"># sentence end boundaries</span></span><br><span class="line">            <span class="keyword">for</span> sep <span class="keyword">in</span> (<span class="string">&quot;. &quot;</span>, <span class="string">&quot;? &quot;</span>, <span class="string">&quot;! &quot;</span>, <span class="string">&quot;.\n&quot;</span>, <span class="string">&quot;?\n&quot;</span>, <span class="string">&quot;!\n&quot;</span>):</span><br><span class="line">                pos = chunk.rfind(sep)</span><br><span class="line">                <span class="keyword">if</span> pos &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># include the punctuation/separator in the chunk (pos + len(sep))</span></span><br><span class="line">                    cut_candidates.append(pos + <span class="built_in">len</span>(sep))</span><br><span class="line">            <span class="keyword">if</span> cut_candidates:</span><br><span class="line">                cut = <span class="built_in">max</span>(cut_candidates)</span><br><span class="line">                chunk = chunk[:cut]</span><br><span class="line">                i += cut</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># fallback: hard cut</span></span><br><span class="line">                i += chunk_chars</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            i += chunk_chars</span><br><span class="line">        chunks.append(chunk)</span><br><span class="line">    <span class="keyword">return</span> chunks</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Ollama API interaction</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_text_in_obj</span>(<span class="params">obj: <span class="type">Any</span></span>) -&gt; <span class="type">Optional</span>[<span class="built_in">str</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Recursively find the first string-like text in a nested JSON object.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> obj <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">str</span>):</span><br><span class="line">        s = obj.strip()</span><br><span class="line">        <span class="keyword">if</span> s:</span><br><span class="line">            <span class="keyword">return</span> s</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">dict</span>):</span><br><span class="line">        <span class="comment"># prefer common keys</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> (<span class="string">&quot;content&quot;</span>, <span class="string">&quot;text&quot;</span>, <span class="string">&quot;output_text&quot;</span>, <span class="string">&quot;message&quot;</span>, <span class="string">&quot;response&quot;</span>, <span class="string">&quot;result&quot;</span>):</span><br><span class="line">            <span class="keyword">if</span> key <span class="keyword">in</span> obj:</span><br><span class="line">                found = find_text_in_obj(obj[key])</span><br><span class="line">                <span class="keyword">if</span> found:</span><br><span class="line">                    <span class="keyword">return</span> found</span><br><span class="line">        <span class="comment"># else iterate values</span></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> obj.values():</span><br><span class="line">            found = find_text_in_obj(v)</span><br><span class="line">            <span class="keyword">if</span> found:</span><br><span class="line">                <span class="keyword">return</span> found</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, (<span class="built_in">list</span>, <span class="built_in">tuple</span>)):</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> obj:</span><br><span class="line">            found = find_text_in_obj(item)</span><br><span class="line">            <span class="keyword">if</span> found:</span><br><span class="line">                <span class="keyword">return</span> found</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_assistant_text_from_response</span>(<span class="params">resp: requests.Response</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Try multiple strategies to get assistant output text from response.&quot;&quot;&quot;</span></span><br><span class="line">    text = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        j = resp.json()</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="comment"># fallback: raw text</span></span><br><span class="line">        <span class="keyword">return</span> resp.text.strip()</span><br><span class="line">    <span class="comment"># try find typical places</span></span><br><span class="line">    assistant_text = find_text_in_obj(j)</span><br><span class="line">    <span class="keyword">if</span> assistant_text:</span><br><span class="line">        <span class="keyword">return</span> assistant_text.strip()</span><br><span class="line">    <span class="comment"># fallback: pretty-print json</span></span><br><span class="line">    <span class="keyword">return</span> json.dumps(j, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_ollama_chat_chunk</span>(<span class="params">api_url: <span class="built_in">str</span>, model: <span class="built_in">str</span>, system_prompt: <span class="built_in">str</span>, user_text: <span class="built_in">str</span>, timeout: <span class="built_in">int</span> = <span class="number">600</span>, max_retries: <span class="built_in">int</span> = <span class="number">3</span></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Call Ollama /api/chat with given model and messages.</span></span><br><span class="line"><span class="string">    Returns a dict with keys: status_code, assistant_text, raw_json (if available).</span></span><br><span class="line"><span class="string">    Retries on transient errors.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    payload = &#123;</span><br><span class="line">        <span class="string">&quot;model&quot;</span>: model,</span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: [</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_prompt&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_text&#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&quot;stream&quot;</span>: <span class="literal">False</span></span><br><span class="line">    &#125;</span><br><span class="line">    headers = &#123;<span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span>&#125;</span><br><span class="line">    attempt = <span class="number">0</span></span><br><span class="line">    last_exc = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">while</span> attempt &lt; max_retries:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            r = requests.post(api_url, headers=headers, json=payload, timeout=timeout)</span><br><span class="line">            <span class="keyword">if</span> r.status_code == <span class="number">200</span>:</span><br><span class="line">                assistant_text = extract_assistant_text_from_response(r)</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    raw_json = r.json()</span><br><span class="line">                <span class="keyword">except</span> Exception:</span><br><span class="line">                    raw_json = <span class="literal">None</span></span><br><span class="line">                <span class="keyword">return</span> &#123;<span class="string">&quot;status_code&quot;</span>: r.status_code, <span class="string">&quot;assistant_text&quot;</span>: assistant_text, <span class="string">&quot;raw_json&quot;</span>: raw_json, <span class="string">&quot;resp_text&quot;</span>: r.text&#125;</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># server returned non-200. read content for diagnostics, maybe ratelimit issues</span></span><br><span class="line">                attempt += <span class="number">1</span></span><br><span class="line">                time.sleep(<span class="number">2</span> ** attempt)</span><br><span class="line">                last_exc = RuntimeError(<span class="string">f&quot;Non-200 from Ollama: <span class="subst">&#123;r.status_code&#125;</span>: <span class="subst">&#123;r.text[:<span class="number">400</span>]&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.RequestException <span class="keyword">as</span> e:</span><br><span class="line">            last_exc = e</span><br><span class="line">            attempt += <span class="number">1</span></span><br><span class="line">            time.sleep(<span class="number">2</span> ** attempt)</span><br><span class="line">    <span class="keyword">raise</span> RuntimeError(<span class="string">f&quot;Failed to call Ollama after <span class="subst">&#123;max_retries&#125;</span> attempts. Last error: <span class="subst">&#123;last_exc&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Parse assistant JSON content</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_json_like</span>(<span class="params">s: <span class="built_in">str</span></span>) -&gt; <span class="type">Optional</span>[<span class="type">Dict</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Try to extract JSON object from assistant string.</span></span><br><span class="line"><span class="string">    Finds first outermost &#123;...&#125; and attempts json.loads.</span></span><br><span class="line"><span class="string">    Returns dict or None.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> s:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    s = s.strip()</span><br><span class="line">    <span class="comment"># quick full-parse</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> json.loads(s)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># find first &#123; and last &#125; and try to parse</span></span><br><span class="line">    first = s.find(<span class="string">&quot;&#123;&quot;</span>)</span><br><span class="line">    last = s.rfind(<span class="string">&quot;&#125;&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> first &gt;= <span class="number">0</span> <span class="keyword">and</span> last &gt; first:</span><br><span class="line">        candidate = s[first:last+<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">return</span> json.loads(candidate)</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Embeddings (optional)</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_embeddings_for_chunks</span>(<span class="params">embed_api_url: <span class="built_in">str</span>, embed_model: <span class="built_in">str</span>, chunks: <span class="type">List</span>[<span class="built_in">str</span>], out_path: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Try to call Ollama&#x27;s embedding endpoint. Save embeddings to out_path as JSON lines:</span></span><br><span class="line"><span class="string">      &#123;&quot;idx&quot;: i, &quot;embedding&quot;: [...], &quot;text_preview&quot;: chunk[:200]&#125;</span></span><br><span class="line"><span class="string">    Note: endpoint existence is environment-dependent.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> is_executable_available(<span class="string">&quot;curl&quot;</span>) <span class="keyword">and</span> <span class="keyword">not</span> shutil.which(<span class="string">&quot;curl&quot;</span>):</span><br><span class="line">        <span class="comment"># curl not required, we use requests</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    results = []</span><br><span class="line">    headers = &#123;<span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">for</span> i, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(chunks, desc=<span class="string">&quot;Embedding chunks&quot;</span>)):</span><br><span class="line">        payload = &#123;</span><br><span class="line">            <span class="string">&quot;model&quot;</span>: embed_model,</span><br><span class="line">            <span class="string">&quot;input&quot;</span>: chunk  <span class="comment"># best-effort; some deployments expect &quot;input&quot; or &quot;inputs&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            r = requests.post(embed_api_url, headers=headers, json=payload, timeout=<span class="number">120</span>)</span><br><span class="line">            <span class="keyword">if</span> r.status_code == <span class="number">200</span>:</span><br><span class="line">                j = r.json()</span><br><span class="line">                <span class="comment"># try to find embedding structure</span></span><br><span class="line">                emb = <span class="literal">None</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(j, <span class="built_in">dict</span>):</span><br><span class="line">                    <span class="comment"># common shapes: j[&quot;data&quot;][0][&quot;embedding&quot;] or j[&quot;embedding&quot;]</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="string">&quot;data&quot;</span> <span class="keyword">in</span> j <span class="keyword">and</span> <span class="built_in">isinstance</span>(j[<span class="string">&quot;data&quot;</span>], <span class="built_in">list</span>) <span class="keyword">and</span> j[<span class="string">&quot;data&quot;</span>] <span class="keyword">and</span> <span class="string">&quot;embedding&quot;</span> <span class="keyword">in</span> j[<span class="string">&quot;data&quot;</span>][<span class="number">0</span>]:</span><br><span class="line">                        emb = j[<span class="string">&quot;data&quot;</span>][<span class="number">0</span>][<span class="string">&quot;embedding&quot;</span>]</span><br><span class="line">                    <span class="keyword">elif</span> <span class="string">&quot;embedding&quot;</span> <span class="keyword">in</span> j:</span><br><span class="line">                        emb = j[<span class="string">&quot;embedding&quot;</span>]</span><br><span class="line">                    <span class="keyword">elif</span> <span class="string">&quot;embeddings&quot;</span> <span class="keyword">in</span> j <span class="keyword">and</span> <span class="built_in">isinstance</span>(j[<span class="string">&quot;embeddings&quot;</span>], <span class="built_in">list</span>):</span><br><span class="line">                        emb = j[<span class="string">&quot;embeddings&quot;</span>][<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="comment"># try to find any list of numbers recursively</span></span><br><span class="line">                        <span class="keyword">def</span> <span class="title function_">find_nums</span>(<span class="params">o</span>):</span><br><span class="line">                            <span class="keyword">if</span> <span class="built_in">isinstance</span>(o, <span class="built_in">list</span>) <span class="keyword">and</span> o <span class="keyword">and</span> <span class="built_in">all</span>(<span class="built_in">isinstance</span>(x, (<span class="built_in">int</span>, <span class="built_in">float</span>)) <span class="keyword">for</span> x <span class="keyword">in</span> o):</span><br><span class="line">                                <span class="keyword">return</span> o</span><br><span class="line">                            <span class="keyword">if</span> <span class="built_in">isinstance</span>(o, <span class="built_in">dict</span>):</span><br><span class="line">                                <span class="keyword">for</span> v <span class="keyword">in</span> o.values():</span><br><span class="line">                                    f = find_nums(v)</span><br><span class="line">                                    <span class="keyword">if</span> f:</span><br><span class="line">                                        <span class="keyword">return</span> f</span><br><span class="line">                            <span class="keyword">if</span> <span class="built_in">isinstance</span>(o, <span class="built_in">list</span>):</span><br><span class="line">                                <span class="keyword">for</span> item <span class="keyword">in</span> o:</span><br><span class="line">                                    f = find_nums(item)</span><br><span class="line">                                    <span class="keyword">if</span> f:</span><br><span class="line">                                        <span class="keyword">return</span> f</span><br><span class="line">                            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">                        emb = find_nums(j)</span><br><span class="line">                <span class="keyword">if</span> emb <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;Warning: could not parse embedding response for chunk <span class="subst">&#123;i&#125;</span>. Saving raw response.&quot;</span>)</span><br><span class="line">                    results.append(&#123;<span class="string">&quot;idx&quot;</span>: i, <span class="string">&quot;embedding&quot;</span>: <span class="literal">None</span>, <span class="string">&quot;raw&quot;</span>: j, <span class="string">&quot;text_preview&quot;</span>: chunk[:<span class="number">200</span>]&#125;)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    results.append(&#123;<span class="string">&quot;idx&quot;</span>: i, <span class="string">&quot;embedding&quot;</span>: emb, <span class="string">&quot;text_preview&quot;</span>: chunk[:<span class="number">200</span>]&#125;)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Embedding call failed for chunk <span class="subst">&#123;i&#125;</span>: <span class="subst">&#123;r.status_code&#125;</span> <span class="subst">&#123;r.text[:<span class="number">400</span>]&#125;</span>&quot;</span>)</span><br><span class="line">                results.append(&#123;<span class="string">&quot;idx&quot;</span>: i, <span class="string">&quot;embedding&quot;</span>: <span class="literal">None</span>, <span class="string">&quot;error&quot;</span>: r.text[:<span class="number">400</span>], <span class="string">&quot;text_preview&quot;</span>: chunk[:<span class="number">200</span>]&#125;)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Exception during embedding chunk <span class="subst">&#123;i&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            results.append(&#123;<span class="string">&quot;idx&quot;</span>: i, <span class="string">&quot;embedding&quot;</span>: <span class="literal">None</span>, <span class="string">&quot;error&quot;</span>: <span class="built_in">str</span>(e), <span class="string">&quot;text_preview&quot;</span>: chunk[:<span class="number">200</span>]&#125;)</span><br><span class="line">    <span class="comment"># write results</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(out_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(results, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Saved embeddings results to <span class="subst">&#123;out_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Merge revised chunks</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_revised_chunks</span>(<span class="params">results_dir: <span class="built_in">str</span>, out_md: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Scan results_dir for files named edited_chunk_&#123;idx&#125;.json and merge</span></span><br><span class="line"><span class="string">    their &#x27;revised&#x27; field (or assistant_text fallback) in order.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    files = []</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> os.listdir(results_dir):</span><br><span class="line">        <span class="keyword">if</span> name.startswith(<span class="string">&quot;edited_chunk_&quot;</span>) <span class="keyword">and</span> name.endswith(<span class="string">&quot;.json&quot;</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                idx = <span class="built_in">int</span>(name[<span class="built_in">len</span>(<span class="string">&quot;edited_chunk_&quot;</span>):-<span class="built_in">len</span>(<span class="string">&quot;.json&quot;</span>)])</span><br><span class="line">                files.append((idx, name))</span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">    files.sort()</span><br><span class="line">    merged_parts = []</span><br><span class="line">    <span class="keyword">for</span> idx, name <span class="keyword">in</span> files:</span><br><span class="line">        path = os.path.join(results_dir, name)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            j = json.load(f)</span><br><span class="line">        <span class="comment"># try raw_json -&gt; assistant_text extraction, or use j.get(&quot;assistant_text&quot;)</span></span><br><span class="line">        assistant_text = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(j, <span class="built_in">dict</span>):</span><br><span class="line">            <span class="comment"># first priority: if raw_json exists and contains assistant text we extract</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;raw_json&quot;</span> <span class="keyword">in</span> j <span class="keyword">and</span> j[<span class="string">&quot;raw_json&quot;</span>]:</span><br><span class="line">                assistant_text = find_text_in_obj(j[<span class="string">&quot;raw_json&quot;</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> assistant_text <span class="keyword">and</span> <span class="string">&quot;assistant_text&quot;</span> <span class="keyword">in</span> j:</span><br><span class="line">                assistant_text = j[<span class="string">&quot;assistant_text&quot;</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> assistant_text <span class="keyword">and</span> <span class="string">&quot;resp_text&quot;</span> <span class="keyword">in</span> j:</span><br><span class="line">                assistant_text = j[<span class="string">&quot;resp_text&quot;</span>]</span><br><span class="line">            <span class="comment"># if assistant_text looks like JSON, parse it to get &#x27;revised&#x27;</span></span><br><span class="line">            parsed = extract_json_like(assistant_text <span class="keyword">or</span> <span class="string">&quot;&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> parsed <span class="keyword">and</span> <span class="built_in">isinstance</span>(parsed, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&quot;revised&quot;</span> <span class="keyword">in</span> parsed:</span><br><span class="line">                revised = parsed[<span class="string">&quot;revised&quot;</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># fallback: if j itself contains fields &#x27;assistant_text&#x27; or &#x27;revised&#x27; already</span></span><br><span class="line">                <span class="keyword">if</span> <span class="string">&quot;revised&quot;</span> <span class="keyword">in</span> j <span class="keyword">and</span> <span class="built_in">isinstance</span>(j[<span class="string">&quot;revised&quot;</span>], <span class="built_in">str</span>):</span><br><span class="line">                    revised = j[<span class="string">&quot;revised&quot;</span>]</span><br><span class="line">                <span class="keyword">elif</span> assistant_text:</span><br><span class="line">                    revised = assistant_text</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    revised = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            revised = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="comment"># ensure separation</span></span><br><span class="line">        merged_parts.append(revised.strip())</span><br><span class="line">    combined = <span class="string">&quot;\n\n---\n\n&quot;</span>.join(part <span class="keyword">for</span> part <span class="keyword">in</span> merged_parts <span class="keyword">if</span> part)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(out_md, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(combined)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Merged <span class="subst">&#123;<span class="built_in">len</span>(merged_parts)&#125;</span> parts into <span class="subst">&#123;out_md&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Final pass (global)</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">final_pass_global</span>(<span class="params">api_url: <span class="built_in">str</span>, model: <span class="built_in">str</span>, system_prompt: <span class="built_in">str</span>, combined_md_path: <span class="built_in">str</span>, out_json: <span class="built_in">str</span>, max_chars: <span class="built_in">int</span> = <span class="number">20000</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Run a final book-level pass. If combined is too large, split into big chunks.</span></span><br><span class="line"><span class="string">    Save the model&#x27;s response JSON to out_json.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(combined_md_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        content = f.read()</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(content) &lt;= max_chars:</span><br><span class="line">        <span class="comment"># single pass</span></span><br><span class="line">        resp = call_ollama_chat_chunk(api_url, model, system_prompt + <span class="string">&quot;\n\nThis is a final book-level pass. Provide a single JSON output with keys: revised, edits, notes.&quot;</span>, content)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(out_json, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            json.dump(resp, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Saved final pass result to <span class="subst">&#123;out_json&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># else split into a few large chunks</span></span><br><span class="line">    chunks = chunk_text(content, chunk_chars=max_chars)</span><br><span class="line">    all_responses = []</span><br><span class="line">    <span class="keyword">for</span> i, ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(chunks):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Final-pass chunk <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(chunks)&#125;</span> size=<span class="subst">&#123;<span class="built_in">len</span>(ch)&#125;</span>&quot;</span>)</span><br><span class="line">        prompt = system_prompt + <span class="string">f&quot;\n\nThis is final book pass chunk <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(chunks)&#125;</span>. Provide JSON with keys: revised, edits, notes.\nAlso summarize any cross-chunk consistency issues.&quot;</span></span><br><span class="line">        resp = call_ollama_chat_chunk(api_url, model, prompt, ch)</span><br><span class="line">        all_responses.append(&#123;<span class="string">&quot;idx&quot;</span>: i, <span class="string">&quot;resp&quot;</span>: resp&#125;)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(out_json, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(all_responses, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Saved final pass results to <span class="subst">&#123;out_json&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="comment"># Main orchestration</span></span><br><span class="line"><span class="comment">############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&quot;Ollama edit pipeline for large PDF -&gt; chunk -&gt; Ollama edits -&gt; merge&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;-i&quot;</span>, <span class="string">&quot;--input&quot;</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&quot;Input PDF path&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;-o&quot;</span>, <span class="string">&quot;--outdir&quot;</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&quot;Output directory to store chunks and results&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--api_url&quot;</span>, default=DEFAULT_API, <span class="built_in">help</span>=<span class="string">&quot;Ollama chat API URL (default: %(default)s)&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--model&quot;</span>, default=DEFAULT_MODEL, <span class="built_in">help</span>=<span class="string">&quot;Model name to use on Ollama (default: %(default)s)&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--chunk_chars&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=DEFAULT_CHUNK_CHARS, <span class="built_in">help</span>=<span class="string">&quot;Chunk size in characters (default 16000)&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--ocr&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Try OCR if PDF looks scanned (requires ocrmypdf)&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--pandoc&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;If set, run pandoc to convert combined.md -&gt; final.docx (requires pandoc installed)&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--do_embed&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Generate embeddings via Ollama embed API (best-effort).&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--embed_model&quot;</span>, default=DEFAULT_EMBED_MODEL, <span class="built_in">help</span>=<span class="string">&quot;Embedding model name (default: %(default)s)&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--embed_api&quot;</span>, default=DEFAULT_EMBED_API, <span class="built_in">help</span>=<span class="string">&quot;Embedding endpoint URL (default: %(default)s)&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--final_pass&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Run final book-level pass after merging (may be large)&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--timeout&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">600</span>, <span class="built_in">help</span>=<span class="string">&quot;API request timeout in seconds&quot;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    inp = args.<span class="built_in">input</span></span><br><span class="line">    outdir = args.outdir</span><br><span class="line">    api_url = args.api_url</span><br><span class="line">    model = args.model</span><br><span class="line">    chunk_chars = args.chunk_chars</span><br><span class="line">    timeout = args.timeout</span><br><span class="line"></span><br><span class="line">    os.makedirs(outdir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    txt_path = os.path.join(outdir, <span class="string">&quot;input_extracted.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Extracting text from <span class="subst">&#123;inp&#125;</span> -&gt; <span class="subst">&#123;txt_path&#125;</span> (use OCR=<span class="subst">&#123;args.ocr&#125;</span>)&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        extract_text_to_file(inp, txt_path, use_ocr=args.ocr)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error extracting text: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        full_text = f.read()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> full_text.strip():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;No text extracted. If the PDF is scanned, retry with --ocr and ensure ocrmypdf is installed.&quot;</span>)</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Chunking text...&quot;</span>)</span><br><span class="line">    chunks = chunk_text(full_text, chunk_chars=chunk_chars)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Created <span class="subst">&#123;<span class="built_in">len</span>(chunks)&#125;</span> chunks (chunk_chars=<span class="subst">&#123;chunk_chars&#125;</span>).&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># chunk output dir</span></span><br><span class="line">    results_dir = os.path.join(outdir, <span class="string">&quot;chunk_results&quot;</span>)</span><br><span class="line">    os.makedirs(results_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># process chunks</span></span><br><span class="line">    <span class="keyword">for</span> idx, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(chunks, desc=<span class="string">&quot;Processing chunks&quot;</span>)):</span><br><span class="line">        out_json_path = os.path.join(results_dir, <span class="string">f&quot;edited_chunk_<span class="subst">&#123;idx&#125;</span>.json&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(out_json_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Skipping idx <span class="subst">&#123;idx&#125;</span>, result exists: <span class="subst">&#123;out_json_path&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            resp = call_ollama_chat_chunk(api_url, model, SYSTEM_PROMPT, chunk, timeout=timeout)</span><br><span class="line">            <span class="comment"># save resp dict with some metadata</span></span><br><span class="line">            dump = &#123;</span><br><span class="line">                <span class="string">&quot;index&quot;</span>: idx,</span><br><span class="line">                <span class="string">&quot;chunk_chars&quot;</span>: <span class="built_in">len</span>(chunk),</span><br><span class="line">                <span class="string">&quot;timestamp&quot;</span>: <span class="built_in">int</span>(time.time()),</span><br><span class="line">                <span class="string">&quot;model&quot;</span>: model,</span><br><span class="line">                <span class="string">&quot;api_url&quot;</span>: api_url,</span><br><span class="line">                <span class="string">&quot;assistant_text&quot;</span>: resp.get(<span class="string">&quot;assistant_text&quot;</span>),</span><br><span class="line">                <span class="string">&quot;raw_json&quot;</span>: resp.get(<span class="string">&quot;raw_json&quot;</span>),</span><br><span class="line">                <span class="string">&quot;resp_text&quot;</span>: resp.get(<span class="string">&quot;resp_text&quot;</span>),</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(out_json_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                json.dump(dump, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error processing chunk <span class="subst">&#123;idx&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="comment"># write a minimal error file so we can resume later</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(out_json_path + <span class="string">&quot;.error&quot;</span>, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(<span class="built_in">str</span>(e))</span><br><span class="line">            <span class="comment"># continue processing remaining chunks</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># merge revised chunks to combined.md</span></span><br><span class="line">    combined_md = os.path.join(outdir, <span class="string">&quot;combined.md&quot;</span>)</span><br><span class="line">    merge_revised_chunks(results_dir, combined_md)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># optional embeddings</span></span><br><span class="line">    <span class="keyword">if</span> args.do_embed:</span><br><span class="line">        emb_out = os.path.join(outdir, <span class="string">&quot;embeddings.json&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Generating embeddings (best-effort)...&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            generate_embeddings_for_chunks(args.embed_api, args.embed_model, chunks, emb_out)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Embeddings generation failed: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># optional pandoc convert</span></span><br><span class="line">    <span class="keyword">if</span> args.pandoc:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> is_executable_available(<span class="string">&quot;pandoc&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;pandoc not found. Please install pandoc to enable conversion.&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            docx_path = os.path.join(outdir, <span class="string">&quot;final.docx&quot;</span>)</span><br><span class="line">            cmd = [<span class="string">&quot;pandoc&quot;</span>, combined_md, <span class="string">&quot;-o&quot;</span>, docx_path]</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Running pandoc to produce DOCX...&quot;</span>)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                run_cmd_check(cmd)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Generated <span class="subst">&#123;docx_path&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Pandoc conversion failed: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># optional final pass</span></span><br><span class="line">    <span class="keyword">if</span> args.final_pass:</span><br><span class="line">        final_json = os.path.join(outdir, <span class="string">&quot;final_pass.json&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Running final pass (may take long depending on book size) ...&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            final_pass_global(api_url, model, SYSTEM_PROMPT, combined_md, final_json)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Final pass failed: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Pipeline finished. Check outputs in:&quot;</span>, outdir)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Notes:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; - If you see .error files next to chunk JSON, inspect them and re-run those chunks later.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; - You can resume by re-running with same args; existing edited_chunk_*.json files are skipped.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; - Adjust --chunk_chars smaller if you hit memory/timeout issues with your model.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/Cherises/">Leonardo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://cherises.github.io/2025/09/25/%E8%B0%83%E7%94%A8%E6%9C%AC%E5%9C%B0Ollama%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%95%B4%E7%90%86PDF%E4%B8%BAMD%E7%9A%84Pytohn%E8%84%9A%E6%9C%AC/">https://cherises.github.io/2025/09/25/%E8%B0%83%E7%94%A8%E6%9C%AC%E5%9C%B0Ollama%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%95%B4%E7%90%86PDF%E4%B8%BAMD%E7%9A%84Pytohn%E8%84%9A%E6%9C%AC/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://github.com/Cherises/">Leonardo</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Ollama/">Ollama</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E8%84%9A%E6%9C%AC/">脚本</a></div><div class="post-share"><div class="social-share" data-image="/img/actor-1.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related  no-desc" href="/2025/09/25/%E5%85%B3%E4%BA%8E%E6%95%99%E5%9F%B9%E6%9C%BA%E6%9E%84%E7%9A%84%E6%80%9D%E8%80%83/" title="关于教培机构的思考"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">关于教培机构的思考</div></div></div></a><a class="pagination-related" href="/2025/09/25/%E5%90%84%E8%A1%8C%E5%90%84%E4%B8%9A%E8%BF%90%E8%90%A5%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE%E7%AC%AC%E5%8D%81%E7%AF%87/" title="各行各业运营知识地图第十篇"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">各行各业运营知识地图第十篇</div></div><div class="info-2"><div class="info-item-1">视频号入门指南.jpg 视频号思维导图.png 视频号直播地图.jpg 视频号知识地图 斜杠了青年.jpg 视频号营销知识图谱.png 视频号运营地图.png 视频号运营思维导图.png 记忆方法地图.jpg 读懂一本书-樊登读书法.jpg 谷歌SEO获客知识地图.jpg 运营100问10：如何构建你的用户体系？.jpg 运营100问11：依照产品生命周期理论，如何在产品的引入期做好产品的口碑？.jpg 运营100问12：电商类产品的运营方法，主要说说系统层面.png 运营100问13：做社区用户运营的关键点是什么，怎样才能和用户保持良好的互动呢？.jpg 运营100问14：如何复盘一场活动？.jpg 运营100问15：运营如何做年度总结与年度计划？.png 运营100问1：什么样的人适合做运营？.jpg 运营100问2：精通运营&#x3D;全栈运营？.jpg 运营100问3：如何运营一款新产品？.jpg 运营100问4：如何多维度思考运营策划与制定运营策略？.jpg 运营100问5：如何规划我的运营职业生涯？.jpg 运营100问6：运营要如何使用数据？.jpg 运营100问7...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/09/25/%E8%B0%83%E7%94%A8%E6%9C%AC%E5%9C%B0Ollama%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%95%B4%E7%90%86%E6%96%87%E4%BB%B6%E5%88%97%E8%A1%A8%E4%B8%BAMD%E7%9A%84Pytohn%E8%84%9A%E6%9C%AC/" title="调用本地Ollama大模型整理文件列表为MD的Pytohn脚本"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-24</div><div class="info-item-2">调用本地Ollama大模型整理文件列表为MD的Pytohn脚本</div></div><div class="info-2"><div class="info-item-1">案例一 前情提要：我有一个700多文档的文件夹，然后需要编写博客，如果我一个一个抄写到博客里面很麻烦，于是我想着可不可以写一个Python脚本，获取当前目录下的所有文件，然后依次遍历，把文件名交给本地大模型，让它返回我所需要的格式(格式要求在代码中)，最好整理成一篇文章，于是就有了下面的两个案例。   获取当前目录下的所有文件（排除脚本自身）。  逐个把文件名传给 ollama 本地模型 qwen2.5:7b。  指定 prompt，让模型 严格输出你需要的格式： 12##文件名 [文件名](https://raw.githubusercontent.com/Cherises/Blog-Resource/main/file/各行业工作总结大全734份/文件名) 把每次结果打印到终端，并最终写入一个 output.md 文件。   代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import osimp...</div></div></div></a><a class="pagination-related" href="/2025/09/14/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%88%86%E5%9D%97%E8%BD%AC%E8%AF%91pdf%E4%B8%BAmd/" title="大模型分块转译pdf为md"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-13</div><div class="info-item-2">大模型分块转译pdf为md</div></div><div class="info-2"><div class="info-item-1">前情提要本来是想把很多字的pdf转为方便修改格式的md，然后保存到笔记里面，但是使用别的大模型，不是不能转，就是缺段少字，主旨就是要分段，一次处理内容过少，所以还是自己写个脚本来实现分段，由于自己写脚本还需要调用大模型API，所以干脆直接调用本地Ollama的吧 流程（PDF 抽取→按字符切块→逐块调用 Ollama /api/chat 编辑→保存每块编辑结果→合并为 Markdown → 可选用 pandoc 转 Word → 可选做合并后全书 final pass → 可选生成 embeddings）。 把下面代码保存为 ollama_edit_pipeline.py，按脚本顶部的说明安装依赖并运行。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/actor-1.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Leonardo</div><div class="author-info-description">Focus on thinking, imagination, reasoning, truth-seeking, and pragmatism</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">56</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">59</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Cherises/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/xxxxx" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:zhaozhinet@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/25/%E5%85%B3%E4%BA%8E%E6%95%99%E5%9F%B9%E6%9C%BA%E6%9E%84%E7%9A%84%E6%80%9D%E8%80%83/" title="关于教培机构的思考">关于教培机构的思考</a><time datetime="2025-09-25T14:39:03.000Z" title="Created 2025-09-25 14:39:03">2025-09-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/25/%E8%B0%83%E7%94%A8%E6%9C%AC%E5%9C%B0Ollama%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%95%B4%E7%90%86PDF%E4%B8%BAMD%E7%9A%84Pytohn%E8%84%9A%E6%9C%AC/" title="调用本地Ollama大模型整理PDF为MD的Pytohn脚本">调用本地Ollama大模型整理PDF为MD的Pytohn脚本</a><time datetime="2025-09-25T10:21:30.000Z" title="Created 2025-09-25 10:21:30">2025-09-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/25/%E5%90%84%E8%A1%8C%E5%90%84%E4%B8%9A%E8%BF%90%E8%90%A5%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE%E7%AC%AC%E5%8D%81%E7%AF%87/" title="各行各业运营知识地图第十篇">各行各业运营知识地图第十篇</a><time datetime="2025-09-24T18:06:53.000Z" title="Created 2025-09-24 18:06:53">2025-09-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/25/%E5%90%84%E8%A1%8C%E5%90%84%E4%B8%9A%E8%BF%90%E8%90%A5%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE%E7%AC%AC%E4%B9%9D%E7%AF%87/" title="各行各业运营知识地图第九篇">各行各业运营知识地图第九篇</a><time datetime="2025-09-24T18:06:51.000Z" title="Created 2025-09-24 18:06:51">2025-09-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/25/%E5%90%84%E8%A1%8C%E5%90%84%E4%B8%9A%E8%BF%90%E8%90%A5%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE%E7%AC%AC%E5%85%AB%E7%AF%87/" title="各行各业运营知识地图第八篇">各行各业运营知识地图第八篇</a><time datetime="2025-09-24T18:06:49.000Z" title="Created 2025-09-24 18:06:49">2025-09-24</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2021 - 2025 By Leonardo</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"></div><div id="global-aplayer" class="aplayer no-destroy" data-fixed="true"></div><script> fetch("/playlist.json") .then(r => r.json()) .then(list => { window.globalAPlayer = new APlayer({ container: document.getElementById("global-aplayer"), fixed: true, mutex: true, autoplay: false, audio: list }); }) .catch(e => console.error("load playlist failed", e)); </script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="false"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script>(() => {
  const destroyAplayer = () => {
    if (window.aplayers) {
      for (let i = 0; i < window.aplayers.length; i++) {
        if (!window.aplayers[i].options.fixed) {
          window.aplayers[i].destroy()
        }
      }
    }
  }

  const runMetingJS = () => {
    typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()
  }

  btf.addGlobalFn('pjaxSend', destroyAplayer, 'destroyAplayer')
  btf.addGlobalFn('pjaxComplete', loadMeting, 'runMetingJS')
})()</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      false
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章🔍" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script data-pjax src="https://unpkg.com/oh-my-live2d"></script><script>const oml2d = OML2D.loadOml2d({menus:{items:[]},libraryUrls:{"complete":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/complete.js","cubism2":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism2.js","cubism5":"https://cdn.jsdelivr.net/npm/live2dcubismcore@5.1.0/live2dcubismcore.min.js"},mobileDisplay:false,models:[{"path":"/models/bilibili-22/index.json","mobilePosition":[-10,23],"mobileScale":0.1,"mobileStageStyle":{"width":180,"height":166},"motionPreloadStrategy":"IDLE","position":[-10,35],"scale":0.15,"stageStyle":{"width":300,"height":280}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:false,tips:{style: {"width":230,"height":120,"left":"calc(50% - 20px)","top":"-100px"},mobileStyle: {"width":180,"height":80,"left":"calc(50% - 30px)","top":"-100px"},idleTips:{interval:15000,message:["你好呀~😊","欢迎来到我的博客~o(*￣▽￣*)ブ","今天过得怎么样呀？(●'◡'●)","发现一个认真阅读的小可爱！","要一起学习吗？(✧ω✧)","今天也是充满希望的一天！☀️","今天有什么计划吗？🎉","嘿嘿，被我发现了哦~😏","代码写累了？休息一下吧~💻","你知道吗？你笑起来很好看！😄","要不要听个笑话？😜","悄悄告诉你个秘密...🤫","哇！你翻到这里了，好厉害！👏","今天有遇到什么有趣的事吗？🎈","保持好奇心是很棒的事情呢！🔍","阅读让世界更美好~📚","嘿！别戳我啦，好痒~>_<~","天气转凉了，记得添件衣服哦~🍂","周末宅家还是出门玩呢？🏠🌳","发现一枚小可爱！(ฅ>ω<*ฅ)","要喝杯水休息一下吗？💧","你的支持是我最大的动力！💪","嘿嘿，我又看到你了哦~👀","今天学习/工作辛苦了！✨","保持微笑，生活会更美好~😊","你知道吗？猫有230根骨头哦！🐱","周末就是要放松一下呢~🛋️","嘿！朋友，最近怎么样？🤗","坚持阅读的人超有魅力！📖","要不要和我一起发呆？(～￣▽￣)～","雨天最适合窝在家里了~☔","你专注的样子真好看！❤️","新的一天，新的开始！🌄","偶尔放松一下也没关系哦~🎵","嘿嘿，猜猜我在想什么？🤔","保持好心情最重要啦！💖","周末有空常来玩呀~🎊","你今天的表现很棒哦！⭐","感谢你的到来和陪伴！🙏","哇，你又来看我啦！(*^▽^*)","今天有什么新鲜事分享吗？🌟","要记得按时吃饭哦~🍚","嘿嘿，偷偷告诉你个小秘密...🤐","你真是我最忠实的读者呢！❤️","窗外阳光真好，要不要出去走走？☀️","深夜党注意休息时间啦~🌙","新技能get了吗？📚","今天也要保持好心情哦！💕","猜猜我今天换了什么发型？💇","周末打算去哪里玩呢？🎡","嘿嘿，我又学会了一个新动作！💃","保持好奇心是很好的品质呢！🔍","要喝杯咖啡提神吗？☕","你真是越来越厉害了呢！👑","雨天最适合在家看书了~📖","今天遇到什么开心的事了吗？🎉","保持微笑，好运自然来~😊","要不要听我唱首歌？🎵","冬天来了，记得多穿点~❄️","发现一枚认真学习的学霸！🏆","周末宅家也是一种享受呢~🏠","你今天看起来特别精神！✨","要适当让眼睛休息一下哦~👀","嘿嘿，我又发现你了！🔎","今天学到了什么新知识？🧠","保持积极心态很重要呢！💪","要不要一起看星星？⭐","春天来了，花儿都开了呢~🌷","你真是我的超级粉丝！🥰","深夜写作灵感爆发期？📝","今天也要努力加油哦！🔥","周末愉快，放松一下~🎶","嘿嘿，我又长高了一点！📏","保持阅读习惯很棒呢！📚","要记得经常活动一下身体~🏃","你今天特别好看哦！💖","夏天到了，注意防暑~🍉","发现一个专注的小可爱！🐰","今天有什么目标要完成？🎯","保持热情，追逐梦想~🌈","要不要一起喝茶聊天？🍵","秋天收获的季节到了~🍂","你真是我最喜欢的访客！🤗","清晨是最佳学习时间哦~🌅","今天也要保持微笑！😄","周末计划去哪里探险？🗺️","嘿嘿，我又变聪明了一点！🧠","保持学习态度很优秀呢！🎓","要记得多补充水分哦~💦","你今天格外有魅力！💫","冬天暖洋洋的被窝最舒服~🛏️","发现一个坚持不懈的战士！⚔️","今天有什么新发现？🔭","保持耐心，好事会发生~🕰️","要不要一起做运动？🏀","春天播种希望的季节~🌱","你真是我的灵感源泉！💡","午后小憩一会儿也不错~😴","今天也要充满活力！⚡","周末享受慢生活时光~🐌","嘿嘿，我又学会新技能！🎨","保持思考习惯很厉害呢！🤔","要记得保护眼睛健康~👓","你今天气场全开！👑","夏天海边吹风最惬意~🌊","发现一个创造力爆棚的天才！🎭","今天有什么奇思妙想？💭","保持乐观，困难会过去~🌤️","要不要一起看场电影？🎬","秋天登高望远好时节~🏔️","你真是我的幸运星！🍀","傍晚散步放松心情~🌇","今天也要相信自己！🌟","周末家庭团聚时光~👨‍👩‍👧‍👦","嘿嘿，我又进步了一点！📈","保持求知欲很棒呢！🔬","要记得保持正确坐姿~💺","你今天闪闪发光！✨","冬天热腾腾的火锅最棒~🍲","发现一个勇于挑战的勇者！🛡️","今天有什么新突破？🚀","保持善良，世界更美好~🌍","要不要一起做美食？🍳","春天野餐郊游正当时~🧺","你真是我的能量来源！🔋","午夜灵感最丰富时刻~🌌","今天也要勇往直前！🏃‍♂️","周末朋友聚会欢乐多~🎊","嘿嘿，我又成长了一些！🌱","保持探索精神很赞呢！🗺️","要记得深呼吸放松~🌬️","你今天魅力无限！💫","夏天冰镇西瓜最解暑~🍉","发现一个善于思考的智者！📚","今天有什么新创意？🎨","保持真诚，友谊长久~🤝","要不要一起看日落？🌅","秋天收获成果的时刻~🍎","你真是我的开心果！😄"]}}});</script><!-- hexo injector body_end end --></body></html>